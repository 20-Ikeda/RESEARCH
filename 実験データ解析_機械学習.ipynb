{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 0: 環境設定（全セル共通で利用）=====\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Callable, Dict, Optional\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ------------------------\n",
    "# 実験スイッチ（Notebook全体で共有）\n",
    "# ------------------------\n",
    "FMS_THRESHOLD: int = 1            # FMS >= 1 を陽性ラベルとみなす\n",
    "EPOCH_LEN: int = 30               # 30 / 60 / 120 のいずれか\n",
    "MODEL_BACKEND: str = \"xgb\"        # \"xgb\" / \"rf\" / \"svm\"\n",
    "USE_AP_FOR_K: bool = False         # APベースの best_k で上書きするか      # 表示用\n",
    "SEED_BASE: int = 20251101\n",
    "\n",
    "if EPOCH_LEN not in (30, 60, 120):\n",
    "    raise ValueError(\"EPOCH_LEN は 30/60/120 から選択してください。\")\n",
    "\n",
    "# ------------------------\n",
    "# ファイル入出力ルート\n",
    "# ------------------------\n",
    "BASE_INPUT_DIR = r\"C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\本実験結果\"\n",
    "BASE_ANALYSIS_DIR = os.path.join(BASE_INPUT_DIR, \"ANALYSIS\")\n",
    "OUT_DIR = os.path.join(BASE_ANALYSIS_DIR, \"機械学習(MSSQ込み)\", f\"閾値FMS{FMS_THRESHOLD}_区間{EPOCH_LEN}\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def outpath(filename: str) -> str:\n",
    "    return os.path.join(OUT_DIR, filename)\n",
    "\n",
    "print(f\"[OUT_DIR] {OUT_DIR}  |  EPOCH_LEN={EPOCH_LEN}s\")\n",
    "\n",
    "# ------------------------\n",
    "# 対象被験者・時間窓\n",
    "# ------------------------\n",
    "SUBJECT_IDS = [\n",
    "    \"10061\",\"10063\",\"10064\",\n",
    "    \"10071\",\"10072\",\"10073\",\"10074\",\n",
    "    \"10081\",\"10082\",\"10083\",\n",
    "    \"10091\",\"10092\",\"10093\",\"10094\",\n",
    "    \"10101\",\"10102\",\"10103\",\n",
    "]\n",
    "\n",
    "BASELINE_EPOCH = 1770               # ベースライン行（必須）\n",
    "ML_START, ML_END = 1800, 2400       # 学習に使う epoch_start 範囲 [start, end)\n",
    "\n",
    "# ------------------------\n",
    "# 描画スタイル\n",
    "# ------------------------\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 120, \"savefig.dpi\": 300,\n",
    "    \"font.size\": 20, \"axes.titlesize\": 26, \"axes.labelsize\": 22,\n",
    "    \"xtick.labelsize\": 20, \"ytick.labelsize\": 20, \"legend.fontsize\": 20,\n",
    "})\n",
    "\n",
    "# ------------------------\n",
    "# FMS二値化ヘルパ\n",
    "# ------------------------\n",
    "def binarize_fms(series: pd.Series, threshold: Optional[int] = None) -> pd.Series:\n",
    "    th = FMS_THRESHOLD if threshold is None else int(threshold)\n",
    "    return (series >= th).astype(int)\n",
    "\n",
    "# ------------------------\n",
    "# モデルレジストリ\n",
    "# ------------------------\n",
    "ModelBuilder = Callable[..., Any]\n",
    "MODEL_REGISTRY: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "def register_backend(name: str, params: Dict[str, Any], builder: ModelBuilder) -> None:\n",
    "    MODEL_REGISTRY[name] = {\"params\": params, \"builder\": builder}\n",
    "\n",
    "def _build_xgb(params: Dict[str, Any], *, scale_pos_weight: Optional[float] = None):\n",
    "    cfg = params.copy()\n",
    "    if scale_pos_weight is not None:\n",
    "        cfg[\"scale_pos_weight\"] = float(scale_pos_weight)\n",
    "    return xgb.XGBClassifier(**cfg)\n",
    "\n",
    "def _build_rf(params: Dict[str, Any], **_):\n",
    "    return RandomForestClassifier(**params)\n",
    "\n",
    "def _build_svm(params: Dict[str, Any], **_):\n",
    "    return SVC(**params)\n",
    "\n",
    "XGB_PARAMS: Dict[str, Any] = dict(\n",
    "    n_estimators=100,\n",
    "    eval_metric=\"logloss\",\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=1.0,\n",
    "    n_jobs=1,\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cpu\",\n",
    "    seed=0,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "RF_PARAMS: Dict[str, Any] = dict(\n",
    "    n_estimators=439,\n",
    "    max_depth=14,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=False,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED_BASE,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "SVM_PARAMS: Dict[str, Any] = dict(\n",
    "    C=1.0,\n",
    "    kernel=\"rbf\",\n",
    "    gamma=\"scale\",\n",
    "    probability=True,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED_BASE,\n",
    ")\n",
    "\n",
    "register_backend(\"xgb\", XGB_PARAMS, _build_xgb)\n",
    "register_backend(\"rf\",  RF_PARAMS,  _build_rf)\n",
    "register_backend(\"svm\", SVM_PARAMS, _build_svm)\n",
    "\n",
    "def set_model_backend(name: str) -> None:\n",
    "    name = name.lower()\n",
    "    if name not in MODEL_REGISTRY:\n",
    "        raise KeyError(f\"[ERROR] backend '{name}' は未登録: {list(MODEL_REGISTRY.keys())}\")\n",
    "    global MODEL_BACKEND\n",
    "    MODEL_BACKEND = name\n",
    "\n",
    "def build_estimator(\n",
    "    backend: Optional[str] = None,\n",
    "    *,\n",
    "    scale_pos_weight: Optional[float] = None,\n",
    "    overrides: Optional[Dict[str, Any]] = None,\n",
    "):\n",
    "    name = (backend or MODEL_BACKEND).lower()\n",
    "    if name not in MODEL_REGISTRY:\n",
    "        raise KeyError(f\"[ERROR] backend '{name}' は未登録。\")\n",
    "    base = MODEL_REGISTRY[name][\"params\"].copy()\n",
    "    if overrides:\n",
    "        base.update(overrides)\n",
    "    builder = MODEL_REGISTRY[name][\"builder\"]\n",
    "    return builder(base, scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "def fit_estimator(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    *,\n",
    "    backend: Optional[str] = None,\n",
    "    scale_pos_weight: Optional[float] = None,\n",
    "    overrides: Optional[Dict[str, Any]] = None,\n",
    "):\n",
    "    X_train = X_train.astype(np.float32, copy=False)\n",
    "    y_train = y_train.astype(np.int32, copy=False)\n",
    "    model = build_estimator(\n",
    "        backend=backend, scale_pos_weight=scale_pos_weight, overrides=overrides\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def predict_positive_score(model, X: pd.DataFrame) -> np.ndarray:\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        return np.asarray(model.decision_function(X), dtype=float)\n",
    "    return model.predict(X).astype(float)\n",
    "\n",
    "MODEL_ID = MODEL_BACKEND.upper()\n",
    "print(f\"[INFO] MODEL_BACKEND={MODEL_ID} / SEED={SEED_BASE} / backends={list(MODEL_REGISTRY.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: データ準備（CSV読込 → EPOCH合成 → SUBJECT_META → 行列出力）=====\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------------------------\n",
    "# ① 30秒EPOCH CSVの読み込み・検証\n",
    "# --------------------------------------------\n",
    "def subject_csv_path(sid: str) -> str:\n",
    "    path = os.path.join(BASE_INPUT_DIR, sid, \"EPOCH\", f\"{sid}_epoch.csv\")\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"[Cell1] CSV missing for subject {sid}: {path}\")\n",
    "    return path\n",
    "\n",
    "dfs = []\n",
    "for sid in SUBJECT_IDS:\n",
    "    df = pd.read_csv(subject_csv_path(sid))\n",
    "    if df.shape[1] < 4:\n",
    "        raise ValueError(f\"[Cell1] {sid}: 列数が不足（>=4 必須）\")\n",
    "    df = df.copy()\n",
    "    df.columns = list(df.columns[:3]) + [str(c) for c in df.columns[3:]]\n",
    "    c1, c2, c3 = df.columns[:3]\n",
    "    df = df.rename(columns={c1: \"epoch_start\", c2: \"epoch_end\", c3: \"FMS\"})\n",
    "    df[\"epoch_start\"] = pd.to_numeric(df[\"epoch_start\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"epoch_end\"]   = pd.to_numeric(df[\"epoch_end\"],   errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"FMS\"]         = pd.to_numeric(df[\"FMS\"],         errors=\"coerce\").astype(\"Int64\")\n",
    "    if df[[\"epoch_start\",\"epoch_end\",\"FMS\"]].isna().any().any():\n",
    "        raise ValueError(f\"[Cell1] {sid}: epoch_start/epoch_end/FMS に NaN\")\n",
    "    df.insert(0, \"subject_id\", sid)\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_raw = pd.concat(dfs, ignore_index=True)\n",
    "exclude_feats = {\"HF_power\", \"LF_power\", \"LF_HF_ratio\"}\n",
    "feature_cols_all = [\n",
    "    c for c in combined_raw.columns\n",
    "    if c not in {\"subject_id\",\"epoch_start\",\"epoch_end\",\"FMS\"} and c not in exclude_feats\n",
    "]\n",
    "if not feature_cols_all:\n",
    "    raise RuntimeError(\"[Cell1] 特徴量列が0です。列名や除外設定を確認してください。\")\n",
    "\n",
    "print(f\"[Cell1] Loaded subjects={len(SUBJECT_IDS)}, rows={len(combined_raw)}, features(after drop)={len(feature_cols_all)}\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# ② EPOCH_LEN 秒への合成 + baseline差分 + ラベル生成\n",
    "# --------------------------------------------\n",
    "if (ML_END - ML_START) % EPOCH_LEN != 0:\n",
    "    raise ValueError(f\"[Cell1] ML window {ML_END-ML_START} が EPOCH_LEN={EPOCH_LEN} で割り切れません。\")\n",
    "\n",
    "rows_per_bin = EPOCH_LEN // 30\n",
    "df_out_list = []\n",
    "\n",
    "for sid, sdf in combined_raw.groupby(\"subject_id\", sort=False):\n",
    "    base_row = sdf.loc[sdf[\"epoch_start\"] == BASELINE_EPOCH]\n",
    "    if len(base_row) != 1:\n",
    "        raise ValueError(f\"[Cell1] {sid}: baseline epoch_start=={BASELINE_EPOCH} が見つからない\")\n",
    "    base_vals = base_row[feature_cols_all].astype(float).iloc[0]\n",
    "    if base_vals.isna().any():\n",
    "        raise ValueError(f\"[Cell1] {sid}: baselineにNaN -> {base_vals.index[base_vals.isna()].tolist()}\")\n",
    "\n",
    "    sdf_ml = sdf[(sdf[\"epoch_start\"] >= ML_START) & (sdf[\"epoch_start\"] < ML_END)].copy()\n",
    "    if sdf_ml.empty:\n",
    "        raise ValueError(f\"[Cell1] {sid}: ML window [{ML_START},{ML_END}) が空です。\")\n",
    "\n",
    "    sdf_ml[\"bin_start\"] = ML_START + ((sdf_ml[\"epoch_start\"] - ML_START) // EPOCH_LEN) * EPOCH_LEN\n",
    "    sdf_ml[\"bin_end\"]   = sdf_ml[\"bin_start\"] + EPOCH_LEN\n",
    "\n",
    "    bin_counts = sdf_ml.groupby([\"bin_start\",\"bin_end\"]).size()\n",
    "    complete_bins = bin_counts[bin_counts == rows_per_bin].index\n",
    "    sdf_ml = sdf_ml.set_index([\"bin_start\",\"bin_end\"]).loc[complete_bins].reset_index()\n",
    "    if sdf_ml.empty:\n",
    "        raise ValueError(f\"[Cell1] {sid}: EPOCH_LEN={EPOCH_LEN} で完全なbinが無い\")\n",
    "\n",
    "    agg_dict = {c: \"mean\" for c in feature_cols_all}\n",
    "    agg_dict[\"FMS\"] = \"mean\"\n",
    "    g = sdf_ml.groupby([\"subject_id\",\"bin_start\",\"bin_end\"], as_index=False).agg(agg_dict)\n",
    "\n",
    "    g_features = g[feature_cols_all].astype(float) - base_vals.values\n",
    "    if g_features.isna().any().any():\n",
    "        bad = g_features.columns[g_features.isna().any()].tolist()\n",
    "        raise ValueError(f\"[Cell1] {sid}: baseline差分後にNaN -> {bad}\")\n",
    "\n",
    "    g_out = pd.concat([g[[\"subject_id\",\"bin_start\",\"bin_end\",\"FMS\"]], g_features], axis=1)\n",
    "    g_out = g_out.rename(columns={\"bin_start\":\"epoch_start\",\"bin_end\":\"epoch_end\"})\n",
    "    g_out[\"label\"] = binarize_fms(g_out[\"FMS\"])\n",
    "    g_out = g_out[[\"subject_id\",\"epoch_start\",\"epoch_end\",\"FMS\",\"label\"] + feature_cols_all]\n",
    "    df_out_list.append(g_out)\n",
    "\n",
    "df_ml_epoch = pd.concat(df_out_list, ignore_index=True)\n",
    "\n",
    "# --------------------------------------------\n",
    "# ③ SUBJECT_META & MSSQ group\n",
    "# --------------------------------------------\n",
    "CANDIDATE_SCORE_PATHS = [\n",
    "    \"/mnt/data/summary_scores.xlsx\",\n",
    "    os.path.join(BASE_ANALYSIS_DIR, \"summary_scores.xlsx\"),\n",
    "    os.path.join(BASE_ANALYSIS_DIR, \"機械学習\", \"summary_scores.xlsx\"),\n",
    "    os.path.join(BASE_INPUT_DIR, \"summary_scores.xlsx\"),\n",
    "]\n",
    "score_path = next((p for p in CANDIDATE_SCORE_PATHS if os.path.exists(p)), None)\n",
    "if score_path is None:\n",
    "    raise FileNotFoundError(\"[Cell1] summary_scores.xlsx が見つかりません。\")\n",
    "meta_raw = pd.read_excel(score_path, sheet_name=\"Summary\")\n",
    "\n",
    "required = [\"ID\", \"MSSQ\", \"VIMSSQ\"]\n",
    "missing = [c for c in required if c not in meta_raw.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"[Cell1] summary_scores.xlsx に必須列がありません -> {missing}\")\n",
    "\n",
    "meta = meta_raw[required].copy()\n",
    "meta[\"ID\"] = (\n",
    "    meta[\"ID\"].astype(str).str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
    ")\n",
    "for c in [\"MSSQ\", \"VIMSSQ\"]:\n",
    "    meta[c] = pd.to_numeric(meta[c], errors=\"raise\")\n",
    "\n",
    "sid_set = set(map(str, SUBJECT_IDS))\n",
    "meta = meta[meta[\"ID\"].isin(sid_set)].copy()\n",
    "if meta[\"ID\"].duplicated().any():\n",
    "    raise ValueError(f\"[Cell1] ID 重複 -> {meta.loc[meta['ID'].duplicated(), 'ID'].tolist()}\")\n",
    "\n",
    "MSSQ_THRESHOLD_FIXED = 12.0\n",
    "meta[\"MSSQ_group\"] = np.where(meta[\"MSSQ\"] >= MSSQ_THRESHOLD_FIXED, \"High\", \"Low\")\n",
    "SUBJECT_META = (\n",
    "    meta.rename(columns={\"ID\": \"subject_id\"})\n",
    "        .set_index(\"subject_id\")[[\"MSSQ\", \"VIMSSQ\", \"MSSQ_group\"]]\n",
    "        .copy()\n",
    ")\n",
    "SUBJECT_META.to_csv(outpath(\"subject_meta.csv\"), encoding=\"utf-8-sig\")\n",
    "print(f\"[Cell1] SUBJECT_META saved -> {outpath('subject_meta.csv')} (source='{score_path}')\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# ④ 学習行列＆行列保存\n",
    "# --------------------------------------------\n",
    "fname_raw = f\"ML_DATA_DELTA_{EPOCH_LEN}S_RAW.CSV\"\n",
    "df_ml_epoch.to_csv(outpath(fname_raw), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "X_all = df_ml_epoch[feature_cols_all].copy().astype(float)\n",
    "y_all = df_ml_epoch[\"label\"].copy().astype(int)\n",
    "groups = df_ml_epoch[\"subject_id\"].copy()\n",
    "\n",
    "X_all.to_csv(outpath(f\"X_RAW_ALL_{EPOCH_LEN}S.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "X_all.to_csv(outpath(f\"X_SCALED_ALL_{EPOCH_LEN}S.CSV\"), index=False, encoding=\"utf-8-sig\")  # 木系でスケーリング不要\n",
    "pd.DataFrame({\"subject_id\": groups, \"label\": y_all, \"FMS_mean\": df_ml_epoch[\"FMS\"]}).to_csv(\n",
    "    outpath(f\"Y_AND_GROUPS_{EPOCH_LEN}S.CSV\"), index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "print(f\"[Cell1] Saved -> {outpath(fname_raw)} / X_RAW_ALL / X_SCALED_ALL / Y_AND_GROUPS\")\n",
    "print(f\"[Cell1] Matrices ready: X_all={X_all.shape}, y_all={y_all.shape}, SUBJECT_META={SUBJECT_META.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45007fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 2: モデリング共通ヘルパ（fit / SHAP / 評価）=====\n",
    "\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 学習ラッパー（Cell0のレジストリAPIを利用）\n",
    "# --------------------------------------------\n",
    "def fit_classifier(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    *,\n",
    "    backend: Optional[str] = None,\n",
    "    scale_pos_weight: Optional[float] = None,\n",
    "    overrides: Optional[Dict[str, Any]] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Cell0 の fit_estimator を直接包む薄いラッパ。\n",
    "    - SHAP/評価セルから backend を差し替えたい場合のみ backend / overrides を指定する。\n",
    "    \"\"\"\n",
    "    if \"fit_estimator\" not in globals():\n",
    "        raise RuntimeError(\"[Cell2] fit_estimator が未定義です。Cell0 を先に実行してください。\")\n",
    "    X_train = X_train.astype(np.float32, copy=False)\n",
    "    y_train = y_train.astype(np.int32, copy=False)\n",
    "    return fit_estimator(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        backend=backend,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        overrides=overrides,\n",
    "    )\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# TreeSHAP ベースの特徴重要度算出\n",
    "# --------------------------------------------\n",
    "def compute_train_shap_abs_mean(model, X_ref: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    学習データ X_ref 上での平均絶対SHAP値（降順）。\n",
    "    - XGB/RF 等の木モデルを想定（TreeSHAP）。\n",
    "    - SVM など非対応モデルでは ValueError を送出する。\n",
    "    \"\"\"\n",
    "    X_ref = X_ref.astype(np.float32, copy=False)\n",
    "\n",
    "    # 背景データ（最大128行）\n",
    "    bg_n = min(128, len(X_ref))\n",
    "    X_bg = X_ref.sample(n=bg_n, random_state=SEED_BASE) if bg_n >= 2 else X_ref\n",
    "\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(\n",
    "            model,\n",
    "            data=X_bg,\n",
    "            model_output=\"probability\",\n",
    "            feature_perturbation=\"interventional\",\n",
    "        )\n",
    "        sv_any = explainer.shap_values(X_ref)\n",
    "    except Exception:\n",
    "        # probability指定が非対応な場合に raw へフォールバック\n",
    "        explainer = shap.TreeExplainer(\n",
    "            model,\n",
    "            model_output=\"raw\",\n",
    "            feature_perturbation=\"tree_path_dependent\",\n",
    "        )\n",
    "        sv_any = explainer.shap_values(X_ref)\n",
    "\n",
    "    # shap_values の戻り値形状を統一（2D: n_samples × n_features）\n",
    "    classes = getattr(model, \"classes_\", None)\n",
    "    pos_idx = int(np.where(classes == 1)[0][0]) if classes is not None and 1 in list(classes) else -1\n",
    "\n",
    "    if isinstance(sv_any, list):\n",
    "        sv = sv_any[pos_idx]\n",
    "    else:\n",
    "        sv = getattr(sv_any, \"values\", sv_any)\n",
    "        sv = np.asarray(sv)\n",
    "        if sv.ndim == 3:\n",
    "            sv = sv[..., pos_idx]\n",
    "        elif sv.ndim == 1:\n",
    "            sv = sv.reshape(-1, 1)\n",
    "\n",
    "    if sv.shape[1] != X_ref.shape[1]:\n",
    "        raise RuntimeError(\n",
    "            f\"[Cell2] SHAP shape mismatch: sv.shape={sv.shape}, X_ref.shape={X_ref.shape}\"\n",
    "        )\n",
    "\n",
    "    abs_mean = np.mean(np.abs(sv), axis=0)\n",
    "    return pd.Series(abs_mean, index=X_ref.columns, name=\"mean_abs\").sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 評価ユーティリティ\n",
    "# --------------------------------------------\n",
    "def _is_probability_like(scores: np.ndarray) -> bool:\n",
    "    return np.isfinite(scores).all() and 0.0 <= scores.min() and scores.max() <= 1.0\n",
    "\n",
    "\n",
    "def evaluate_fold(model, X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    - ROC AUC: 2クラス時のみ。\n",
    "    - Accuracy: 確率なら 0.5、スコアなら 0.0 を閾値とする（詳細な最適化は別セル）。\n",
    "    \"\"\"\n",
    "    X_test = X_test.astype(np.float32, copy=False)\n",
    "    scores = predict_positive_score(model, X_test)\n",
    "\n",
    "    if len(np.unique(y_test)) == 2:\n",
    "        roc_auc = roc_auc_score(y_test, scores)\n",
    "    else:\n",
    "        roc_auc = float(\"nan\")\n",
    "\n",
    "    thr = 0.5 if _is_probability_like(scores) else 0.0\n",
    "    pred = (scores >= thr).astype(int)\n",
    "    acc = accuracy_score(y_test.astype(int), pred)\n",
    "\n",
    "    return {\"roc_auc\": float(roc_auc), \"accuracy\": float(acc)}\n",
    "\n",
    "\n",
    "print(\"[Cell2] Modeling helpers ready (fit_classifier / compute_train_shap_abs_mean / evaluate_fold)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58071f6d",
   "metadata": {},
   "source": [
    "# ===== Section: 特徴重要度と best_k 探索 =====\n",
    "\n",
    "| Cell | 目的 | 主な出力 (OUT_DIR 配下) |\n",
    "| ---- | ---- | ----------------------- |\n",
    "| 3A | LOSO学習でSHAP重要度を算出しランキング化 | `SHAP_FEATURE_RANKING.CSV`, `SHAP_FEATURE_RANKING_LABELED.CSV`, `SHAP_RANKING_ALL.PNG`, `SHAP_TOP8_RANKING.PNG`, `LOSO_METRICS.CSV` |\n",
    "| 3B | SHAP順の特徴を使って k 本ごとの pooled ROC-AUC を計測し best_k を決定 | `AUC_PER_K.CSV`, `AUC_VS_NUM_FEATURES.PNG`, `best_k` (グローバル変数) |\n",
    "| 3C | 同様に AUPRC/AP で k を走査し、必要に応じ best_k を APベースで上書きし PR 曲線を出力 | `AUPRC_PER_K.CSV`, `AP_VS_NUM_FEATURES.PNG`, `PR_CURVE_AT_BEST_K.CSV`, `PR_CURVE_AT_BEST_K.PNG` |\n",
    "| 3D | MSSQ High/Low 各群で in-group LOSO を行い、群別の AUC vs k と best_k を算出 | `AUC_VS_K_BY_GROUP.PNG`, `BEST_K_BY_GROUP.JSON` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c331d6",
   "metadata": {},
   "source": [
    "# ===== Cell 3A: SHAPランキング（LOSO学習側のみ）=====\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "shap_frames = []\n",
    "metrics_rows = []\n",
    "\n",
    "for fold_id, (tr_idx, te_idx) in enumerate(logo.split(X_all, y_all, groups), start=1):\n",
    "    X_tr, X_te = X_all.iloc[tr_idx], X_all.iloc[te_idx]\n",
    "    y_tr, y_te = y_all.iloc[tr_idx], y_all.iloc[te_idx]\n",
    "    if len(np.unique(y_tr)) < 2:\n",
    "        raise RuntimeError(f\"[Cell3A] fold{fold_id}: 学習側が単一クラス\")\n",
    "\n",
    "    model = fit_classifier(X_tr, y_tr)\n",
    "    abs_mean = compute_train_shap_abs_mean(model, X_tr).rename(f\"fold{fold_id}\")\n",
    "    shap_frames.append(abs_mean)\n",
    "\n",
    "    m = evaluate_fold(model, X_te, y_te)\n",
    "    metrics_rows.append({\n",
    "        \"fold_id\": fold_id,\n",
    "        \"test_subject\": groups.iloc[te_idx].iloc[0],\n",
    "        \"roc_auc\": m[\"roc_auc\"],\n",
    "        \"accuracy\": m[\"accuracy\"],\n",
    "    })\n",
    "\n",
    "shap_rank = pd.concat(shap_frames, axis=1)\n",
    "shap_rank[\"mean_abs\"] = shap_rank.mean(axis=1)\n",
    "shap_rank = shap_rank.sort_values(\"mean_abs\", ascending=False)\n",
    "\n",
    "shap_rank.to_csv(outpath(\"SHAP_FEATURE_RANKING.CSV\"), encoding=\"utf-8-sig\")\n",
    "shap_rank.to_csv(outpath(\"SHAP_FEATURE_RANKING_LABELED.CSV\"), encoding=\"utf-8-sig\")\n",
    "pd.DataFrame(metrics_rows).to_csv(outpath(\"LOSO_METRICS.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"[Cell3A] Saved SHAP ranking & LOSO metrics\")\n",
    "\n",
    "plt.figure(figsize=(10, max(5, len(shap_rank)//3)))\n",
    "plt.barh(shap_rank.index[::-1], shap_rank[\"mean_abs\"][::-1])\n",
    "plt.xlabel(\"Mean |SHAP|\"); plt.ylabel(\"Feature\"); plt.title(\"SHAP Ranking (All)\")\n",
    "plt.tight_layout(); plt.savefig(outpath(\"SHAP_RANKING_ALL.PNG\"), dpi=300); plt.close()\n",
    "\n",
    "topk = shap_rank.head(8).iloc[::-1]\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = plt.gca()\n",
    "ax.barh(topk.index, topk[\"mean_abs\"])\n",
    "mx = float(topk[\"mean_abs\"].max()) if len(topk) else 1.0\n",
    "ax.set_xlim(0, mx * 1.08)\n",
    "ax.set_xlabel(\"Mean |SHAP value|\", fontsize=26)\n",
    "ax.set_ylabel(\"Feature\", fontsize=26)\n",
    "ax.tick_params(axis=\"both\", labelsize=22)\n",
    "ax.set_title(\"Top-8 SHAP Feature Ranking\", fontsize=34, pad=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(outpath(\"SHAP_TOP8_RANKING.PNG\"), dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726eb942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3A (Legacy): SHAPランキング（XGB pred_contribs版） =====\n",
    "# - XGBoost専用（pred_contribs=True）でSHAP値を算出\n",
    "# - 生成物は現行セルと同名ファイルに上書き保存\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "shap_frames = []\n",
    "metrics_rows = []\n",
    "\n",
    "for fold_id, (tr_idx, te_idx) in enumerate(logo.split(X_all, y_all, groups), start=1):\n",
    "    X_tr, X_te = X_all.iloc[tr_idx], X_all.iloc[te_idx]\n",
    "    y_tr, y_te = y_all.iloc[tr_idx], y_all.iloc[te_idx]\n",
    "    if len(np.unique(y_tr)) < 2:\n",
    "        raise RuntimeError(f\"[Cell3A-legacy] fold{fold_id}: 学習側が単一クラスです。\")\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        eval_metric=\"logloss\",\n",
    "        subsample=1.0,\n",
    "        colsample_bytree=1.0,\n",
    "        n_jobs=1,\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cpu\",\n",
    "        seed=0,\n",
    "        random_state=0,\n",
    "    )\n",
    "    model.fit(X_tr.astype(np.float32), y_tr.astype(np.int32))\n",
    "\n",
    "    dm = xgb.DMatrix(X_tr.astype(np.float32), feature_names=list(X_tr.columns))\n",
    "    contribs = model.get_booster().predict(dm, pred_contribs=True)  # (n_samples, n_features+1)\n",
    "    shap_vals = contribs[:, :-1]                                   # 最後の列はバイアス項\n",
    "    abs_mean = np.abs(shap_vals).mean(axis=0)\n",
    "    shap_frames.append(pd.Series(abs_mean, index=X_tr.columns, name=f\"fold{fold_id}\"))\n",
    "\n",
    "    m = evaluate_fold(model, X_te, y_te)\n",
    "    metrics_rows.append({\n",
    "        \"fold_id\": fold_id,\n",
    "        \"test_subject\": groups.iloc[te_idx].iloc[0],\n",
    "        \"roc_auc\": m[\"roc_auc\"],\n",
    "        \"accuracy\": m[\"accuracy\"],\n",
    "    })\n",
    "\n",
    "shap_rank = pd.concat(shap_frames, axis=1)\n",
    "shap_rank[\"mean_abs\"] = shap_rank.mean(axis=1)\n",
    "shap_rank = shap_rank.sort_values(\"mean_abs\", ascending=False)\n",
    "\n",
    "# ★ 既存ファイル名へ上書き保存（現行版と同じパス）\n",
    "shap_rank.to_csv(outpath(\"SHAP_FEATURE_RANKING.CSV\"), encoding=\"utf-8-sig\")\n",
    "shap_rank.to_csv(outpath(\"SHAP_FEATURE_RANKING_LABELED.CSV\"), encoding=\"utf-8-sig\")\n",
    "pd.DataFrame(metrics_rows).to_csv(outpath(\"LOSO_METRICS.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"[Cell3A-legacy] SHAP_FEATURE_RANKING*.CSV を旧ロジックで上書きしました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLA2: SHAP全体ランクへの相関管理（|r|>0.90, Pearson）＋バックアップ＆上書き =====\n",
    "# 前提:\n",
    "#  - outpath(name: str) -> str が定義済みであること\n",
    "#  - X_all: pd.DataFrame がメモリ上に存在すること（全特徴の数値列を含む）\n",
    "#  - 既に Cell 3A を実行し、outpath(\"SHAP_FEATURE_RANKING.CSV\") が存在すること\n",
    "#\n",
    "# 入出力仕様:\n",
    "#  - 入力:  SHAP_FEATURE_RANKING.CSV（Cell3A 生成物）\n",
    "#  - 出力:  同名 CSV を上書き（相関管理後の行のみ残す）\n",
    "#            ただし上書き前の入力CSVは SHAP_FEATURE_RANKING_BEFORE_CORR.CSV に保存\n",
    "#          画像も同様に、既存PNGを *_BEFORE_CORR.PNG に退避し、新たに再描画して上書き\n",
    "#\n",
    "# バックアップ対象画像（存在するもののみ退避）:\n",
    "#  - SHAP_RANKING_ALL.PNG      -> SHAP_RANKING_ALL_BEFORE_CORR.PNG\n",
    "#  - SHAP_TOP8_RANKING.PNG     -> SHAP_TOP8_RANKING_BEFORE_CORR.PNG\n",
    "#\n",
    "# 可視化規約（ユーザー指定）:\n",
    "#  - タイトル 30, 軸ラベル 24, 目盛 20, 凡例 20\n",
    "#  - 線幅 linewidth=1.5\n",
    "#  - 画像 dpi=300, tight_layout\n",
    "#\n",
    "# 注意:\n",
    "#  - 本セルは「リーク回避なし」である（X_all 全体で相関を計算）．\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- ユーティリティ ----------------\n",
    "def _assert(cond: bool, msg: str):\n",
    "    if not cond:\n",
    "        raise RuntimeError(msg)\n",
    "\n",
    "def _backup_file(src_path: str, dst_path: str):\n",
    "    \"\"\"ファイルが存在すれば dst_path へコピーする（存在しなければ何もしない）\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            print(f\"[OK] Backup -> {os.path.basename(dst_path)}\")\n",
    "        else:\n",
    "            print(f\"[SKIP] Not found (no backup): {os.path.basename(src_path)}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"[ERROR] Backup failed: {src_path} -> {dst_path}: {e}\")\n",
    "\n",
    "def _corr_prune_global(\n",
    "    X: pd.DataFrame,\n",
    "    ranked_features: list[str],\n",
    "    method: str = \"pearson\",\n",
    "    thr: float = 0.90,\n",
    "    min_var: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    全体ランク ranked_features（降順）に対し，|r|>thr で冗長特徴を間引く（リーク回避なし）．\n",
    "    戻り値:\n",
    "        kept_order: 採択順（list[str]）\n",
    "        dropped_info: list[dict]  # {\"feature\", \"rep\", \"abs_corr\"}\n",
    "    \"\"\"\n",
    "    # 数値列に限定\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    ranked = [f for f in ranked_features if f in num_cols]\n",
    "    _assert(len(ranked) > 0, \"[CELLA2] 数値列に該当する特徴が無い．\")\n",
    "\n",
    "    # 定数/ほぼ定数列の除外（相関NaN回避）\n",
    "    var = X[ranked].var(axis=0, ddof=1).fillna(0.0)\n",
    "    ranked = [f for f in ranked if var.get(f, 0.0) > min_var]\n",
    "    _assert(len(ranked) > 0, \"[CELLA2] 有効分散のある特徴が無い．\")\n",
    "\n",
    "    # 相関行列（pairwise complete）\n",
    "    R = X[ranked].corr(method=method)\n",
    "\n",
    "    kept, dropped_info = [], []\n",
    "    for f in ranked:\n",
    "        # 既採択との最大相関を評価\n",
    "        if kept:\n",
    "            abs_corrs = [(k, float(abs(R.loc[f, k]))) for k in kept if pd.notna(R.loc[f, k])]\n",
    "            if abs_corrs:\n",
    "                kstar, max_abs = max(abs_corrs, key=lambda t: t[1])\n",
    "            else:\n",
    "                kstar, max_abs = None, 0.0\n",
    "        else:\n",
    "            kstar, max_abs = None, 0.0\n",
    "\n",
    "        if max_abs > thr:\n",
    "            dropped_info.append({\"feature\": f, \"rep\": kstar, \"abs_corr\": max_abs})\n",
    "        else:\n",
    "            kept.append(f)\n",
    "\n",
    "    return kept, dropped_info\n",
    "\n",
    "# ---------------- 入力の存在確認＆バックアップ ----------------\n",
    "rank_csv = outpath(\"SHAP_FEATURE_RANKING.CSV\")\n",
    "_assert(os.path.exists(rank_csv), \"[CELLA2] 入力CSVが存在しない: SHAP_FEATURE_RANKING.CSV\")\n",
    "\n",
    "# 既存PNGのパス\n",
    "png_all = outpath(\"SHAP_RANKING_ALL.PNG\")\n",
    "png_top = outpath(\"SHAP_TOP8_RANKING.PNG\")\n",
    "\n",
    "# バックアップ先\n",
    "rank_csv_bak = outpath(\"SHAP_FEATURE_RANKING_BEFORE_CORR.CSV\")\n",
    "png_all_bak  = outpath(\"SHAP_RANKING_ALL_BEFORE_CORR.PNG\")\n",
    "png_top_bak  = outpath(\"SHAP_TOP8_RANKING_BEFORE_CORR.PNG\")\n",
    "\n",
    "print(\"[INFO] CorrMgmt(global/no-leak): method=pearson, thr=0.90, min_var=0.0\")\n",
    "_backup_file(rank_csv, rank_csv_bak)\n",
    "_backup_file(png_all, png_all_bak)\n",
    "_backup_file(png_top, png_top_bak)\n",
    "\n",
    "# ---------------- ランキング読み込み ----------------\n",
    "shap_rank = pd.read_csv(rank_csv, index_col=0, encoding=\"utf-8-sig\")\n",
    "_assert(\"mean_abs\" in shap_rank.columns, \"[CELLA2] shap_rank に 'mean_abs' 列が無い．Cell3A の完了が必要である．\")\n",
    "\n",
    "# 全体ランク（降順）\n",
    "ranked_features = shap_rank.sort_values(\"mean_abs\", ascending=False).index.tolist()\n",
    "print(f\"[INFO] Ranked features (before corr): n={len(ranked_features)}\")\n",
    "\n",
    "# ---------------- 相関管理の実施（X_all 全体で計算） ----------------\n",
    "_assert(\"X_all\" in globals(), \"[CELLA2] X_all が未定義である．\")\n",
    "kept_order, dropped_info = _corr_prune_global(\n",
    "    X=X_all,\n",
    "    ranked_features=ranked_features,\n",
    "    method=\"pearson\",\n",
    "    thr=0.90,\n",
    "    min_var=0.0,\n",
    ")\n",
    "print(f\"[OK] CorrMgmt: kept={len(kept_order)}, dropped={len(dropped_info)}\")\n",
    "\n",
    "# ---------------- CSVの上書き保存（相関管理後の行のみ） ----------------\n",
    "# 元の shap_rank から、kept のみを抜粋して 'mean_abs' 降順を維持\n",
    "shap_after = shap_rank.loc[kept_order].sort_values(\"mean_abs\", ascending=False)\n",
    "shap_after.to_csv(rank_csv, encoding=\"utf-8-sig\")\n",
    "print(f\"[OK] Overwritten -> {os.path.basename(rank_csv)}\")\n",
    "\n",
    "# 監査用（代表→吸収）のCSVも出しておくと便利である（任意だが有用）\n",
    "if dropped_info:\n",
    "    corr_groups_path = outpath(\"CORR_GROUPS.CSV\")\n",
    "    rows = []\n",
    "    for d in dropped_info:\n",
    "        rows.append({\"representative\": d[\"rep\"], \"absorbed_feature\": d[\"feature\"], \"abs_corr_with_rep\": d[\"abs_corr\"]})\n",
    "    pd.DataFrame(rows).to_csv(corr_groups_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[OK] Saved -> {os.path.basename(corr_groups_path)}\")\n",
    "\n",
    "# ---------------- 可視化（上書き出力；規約のフォントサイズを適用） ----------------\n",
    "def _plot_rank_all(df_sorted: pd.DataFrame, path_png: str, title: str):\n",
    "    plt.figure(figsize=(10, max(5, len(df_sorted)//3)))\n",
    "    ax = plt.gca()\n",
    "    ax.barh(df_sorted.index[::-1], df_sorted[\"mean_abs\"][::-1])\n",
    "    ax.set_xlabel(\"Mean |SHAP value|\", fontsize=24)\n",
    "    ax.set_ylabel(\"Feature\", fontsize=24)\n",
    "    ax.tick_params(axis=\"both\", labelsize=20, width=1.5)\n",
    "    ax.set_title(title, fontsize=30, pad=10)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_png, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def _plot_rank_topk(df_sorted: pd.DataFrame, path_png: str, k: int = 8):\n",
    "    topk = df_sorted.head(k).iloc[::-1]\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    ax = plt.gca()\n",
    "    ax.barh(topk.index, topk[\"mean_abs\"])\n",
    "    mx = float(topk[\"mean_abs\"].max()) if len(topk) else 1.0\n",
    "    ax.set_xlim(0, mx * 1.08)\n",
    "    ax.set_xlabel(\"Mean |SHAP value|\", fontsize=24)\n",
    "    ax.set_ylabel(\"Feature\", fontsize=24)\n",
    "    ax.tick_params(axis=\"both\", labelsize=20, width=1.5)\n",
    "    ax.set_title(f\"Top-{k} SHAP Feature Ranking (after corr |r|>0.90)\", fontsize=30, pad=10)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.5)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_png, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# 再描画（上書き）\n",
    "_plot_rank_all(shap_after.sort_values(\"mean_abs\", ascending=False), png_all, title=\"SHAP Ranking (All, after corr |r|>0.90)\")\n",
    "_plot_rank_topk(shap_after.sort_values(\"mean_abs\", ascending=False), png_top, k=8)\n",
    "print(f\"[OK] Overwritten -> {os.path.basename(png_all)}, {os.path.basename(png_top)}\")\n",
    "\n",
    "print(\"[DONE] CELLA2 完了（全体ランクに相関管理を適用し、CSV/PNGをバックアップの上で上書きした）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3B: 全kで pooled ROC-AUC → best_k 決定 =====\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rank_df = pd.read_csv(outpath(\"SHAP_FEATURE_RANKING.CSV\"), index_col=0, encoding=\"utf-8-sig\")\n",
    "feature_order = [f for f in rank_df.index if f in X_all.columns]\n",
    "if not feature_order:\n",
    "    raise RuntimeError(\"[Cell3B] ランキング上位特徴が X_all に存在しません。\")\n",
    "\n",
    "ks = list(range(len(feature_order), 0, -1))\n",
    "logo = LeaveOneGroupOut()\n",
    "auc_list = []\n",
    "\n",
    "for k in ks:\n",
    "    feats = feature_order[:k]\n",
    "    X = X_all[feats].astype(np.float32)\n",
    "    y = y_all.values\n",
    "    g = groups.values\n",
    "\n",
    "    y_true_all, proba_all = [], []\n",
    "    for tr_idx, te_idx in logo.split(X, y, g):\n",
    "        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "        if len(np.unique(y_tr)) < 2:\n",
    "            raise RuntimeError(\"[Cell3B] 学習foldが単一クラス。閾値/期間の見直しが必要です。\")\n",
    "        model = fit_classifier(X_tr, pd.Series(y_tr))\n",
    "        proba = predict_positive_score(model, X_te)\n",
    "        y_true_all.append(y_te); proba_all.append(proba)\n",
    "\n",
    "    y_true_k = np.concatenate(y_true_all)\n",
    "    proba_k = np.concatenate(proba_all)\n",
    "    if len(np.unique(y_true_k)) < 2:\n",
    "        raise RuntimeError(\"[Cell3B] pooled 真値が単一クラスで AUC 計算不可。\")\n",
    "    auc_list.append(float(roc_auc_score(y_true_k, proba_k)))\n",
    "\n",
    "pd.DataFrame({\"k\": ks, \"auc_pooled\": auc_list}).to_csv(outpath(\"AUC_PER_K.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "auc_array = np.asarray(auc_list, dtype=float)\n",
    "best_idx = int(np.nanargmax(auc_array))\n",
    "best_k = ks[best_idx]\n",
    "best_auc = auc_list[best_idx]\n",
    "print(f\"[Cell3B] Best k (AUC) = {best_k}, AUC={best_auc:.3f}\")\n",
    "globals()[\"best_k\"] = best_k \n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = plt.gca()\n",
    "ax.plot(ks, auc_list, marker='o', linewidth=1.5)\n",
    "ax.scatter([best_k], [best_auc], s=180, color=\"red\", zorder=5)\n",
    "ax.annotate(f\"Max AUC = {best_auc:.3f} (k={best_k})\", xy=(best_k, best_auc),\n",
    "            xytext=(best_k, best_auc + 0.02), ha=\"center\", va=\"bottom\",\n",
    "            fontsize=20, color=\"red\")\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel(\"Number of Features (k)\", fontsize=26)\n",
    "ax.set_ylabel(\"ROC AUC (pooled)\", fontsize=26)\n",
    "ax.tick_params(axis=\"both\", labelsize=22)\n",
    "ax.set_title(\"AUC vs Number of Features\", fontsize=34, pad=10)\n",
    "ax.grid(True, alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(outpath(\"AUC_VS_NUM_FEATURES.PNG\"), dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3C: 全kで pooled AUPRC → best_k (AP) 決定 ＋ PR曲線 =====\n",
    "\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "rank_df = pd.read_csv(outpath(\"SHAP_FEATURE_RANKING.CSV\"), index_col=0, encoding=\"utf-8-sig\")\n",
    "feature_order = [f for f in rank_df.index if f in X_all.columns]\n",
    "if not feature_order:\n",
    "    raise RuntimeError(\"[Cell3C] ランキング上位特徴が X_all に存在しません。\")\n",
    "\n",
    "ks = list(range(len(feature_order), 0, -1))\n",
    "logo = LeaveOneGroupOut()\n",
    "ap_list, prauc_list, pi_list = [], [], []\n",
    "\n",
    "for k in ks:\n",
    "    feats = feature_order[:k]\n",
    "    X = X_all[feats].astype(np.float32)\n",
    "    y = y_all.values\n",
    "    g = groups.values\n",
    "\n",
    "    y_true_all, proba_all = [], []\n",
    "    for tr_idx, te_idx in logo.split(X, y, g):\n",
    "        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "        if len(np.unique(y_tr)) < 2:\n",
    "            raise RuntimeError(\"[Cell3C] 学習foldが単一クラス。\")\n",
    "        model = fit_classifier(X_tr, pd.Series(y_tr))\n",
    "        proba = predict_positive_score(model, X_te)\n",
    "        y_true_all.append(y_te); proba_all.append(proba)\n",
    "\n",
    "    y_true_k = np.concatenate(y_true_all)\n",
    "    proba_k = np.concatenate(proba_all)\n",
    "    if len(np.unique(y_true_k)) < 2:\n",
    "        raise RuntimeError(\"[Cell3C] pooled 真値が単一クラスで AUPRC 計算不可。\")\n",
    "\n",
    "    ap = float(average_precision_score(y_true_k, proba_k))\n",
    "    prec, rec, _ = precision_recall_curve(y_true_k, proba_k)\n",
    "    prauc = float(auc(rec, prec))\n",
    "    ap_list.append(ap)\n",
    "    prauc_list.append(prauc)\n",
    "    pi_list.append(float((y_true_k == 1).mean()))\n",
    "\n",
    "pd.DataFrame({\"k\": ks, \"ap\": ap_list, \"prauc\": prauc_list, \"pi\": pi_list}).to_csv(\n",
    "    outpath(\"AUPRC_PER_K.CSV\"), index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "ap_array = np.asarray(ap_list, dtype=float)\n",
    "best_idx_ap = int(np.nanargmax(ap_array))\n",
    "best_k_ap = ks[best_idx_ap]\n",
    "print(f\"[Cell3C] Best k (AP) = {best_k_ap}, AP={ap_list[best_idx_ap]:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = plt.gca()\n",
    "ax.plot(ks, ap_list, marker='o', linewidth=1.5, label=\"AP\")\n",
    "ax.scatter([best_k_ap], [ap_list[best_idx_ap]], s=150, color=\"red\", zorder=5)\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel(\"Number of Features (k)\", fontsize=26)\n",
    "ax.set_ylabel(\"Average Precision\", fontsize=26)\n",
    "ax.tick_params(axis=\"both\", labelsize=22)\n",
    "ax.set_title(\"AP vs Number of Features\", fontsize=34, pad=10)\n",
    "ax.grid(True, alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(outpath(\"AP_VS_NUM_FEATURES.PNG\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "if USE_AP_FOR_K:\n",
    "    globals()[\"best_k\"] = best_k_ap\n",
    "    print(f\"[Cell3C] USE_AP_FOR_K=True → best_k を {best_k_ap} に上書き\")\n",
    "else:\n",
    "    print(\"[Cell3C] USE_AP_FOR_K=False → Cell3Bの best_k を維持\")\n",
    "\n",
    "feats_best = feature_order[:globals()[\"best_k\"]]\n",
    "logo = LeaveOneGroupOut()\n",
    "y_true_best, proba_best = [], []\n",
    "for tr_idx, te_idx in logo.split(X_all[feats_best], y_all.values, groups.values):\n",
    "    X_tr, X_te = X_all[feats_best].iloc[tr_idx], X_all[feats_best].iloc[te_idx]\n",
    "    y_tr, y_te = y_all.values[tr_idx], y_all.values[te_idx]\n",
    "    if len(np.unique(y_tr)) < 2:\n",
    "        raise RuntimeError(\"[Cell3C] best_k fold が単一クラス。\")\n",
    "    model = fit_classifier(X_tr, pd.Series(y_tr))\n",
    "    proba = predict_positive_score(model, X_te)\n",
    "    y_true_best.append(y_te); proba_best.append(proba)\n",
    "\n",
    "y_true_best = np.concatenate(y_true_best)\n",
    "proba_best = np.concatenate(proba_best)\n",
    "prec, rec, thr = precision_recall_curve(y_true_best, proba_best)\n",
    "ap_best = float(average_precision_score(y_true_best, proba_best))\n",
    "prauc_best = float(auc(rec, prec))\n",
    "pi_best = float((y_true_best == 1).mean())\n",
    "\n",
    "pd.DataFrame({\"recall\": rec, \"precision\": prec, \"threshold\": np.r_[np.nan, thr]}).to_csv(\n",
    "    outpath(\"PR_CURVE_AT_BEST_K.CSV\"), index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "ax = plt.gca()\n",
    "ax.step(rec, prec, where=\"post\", linewidth=1.5,\n",
    "        label=f\"PR (AP={ap_best:.3f}, PR-AUC={prauc_best:.3f})\")\n",
    "ax.axhline(pi_best, linestyle=\"--\", linewidth=1.5, label=f\"Baseline π={pi_best:.3f}\", alpha=0.8)\n",
    "ax.set_xlabel(\"Recall\", fontsize=24)\n",
    "ax.set_ylabel(\"Precision\", fontsize=24)\n",
    "ax.tick_params(axis=\"both\", labelsize=20)\n",
    "ax.set_title(f\"Precision–Recall at best k = {globals()['best_k']}\", fontsize=30, pad=10)\n",
    "ax.set_xlim([0.0, 1.0]); ax.set_ylim([0.0, 1.05])\n",
    "ax.grid(True, alpha=0.4)\n",
    "ax.legend(fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(outpath(\"PR_CURVE_AT_BEST_K.PNG\"), dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3D: MSSQ群別 AUC vs k（in-group LOSO）=====\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import json\n",
    "\n",
    "req_vars = [\"X_all\", \"y_all\", \"groups\", \"SUBJECT_META\"]\n",
    "missing = [v for v in req_vars if v not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"[Cell3D] 必要変数が未定義: {missing}\")\n",
    "if \"MSSQ_group\" not in SUBJECT_META.columns:\n",
    "    raise RuntimeError(\"[Cell3D] SUBJECT_META に MSSQ_group 列が必要です。\")\n",
    "\n",
    "rank_df = pd.read_csv(outpath(\"SHAP_FEATURE_RANKING.CSV\"), index_col=0, encoding=\"utf-8-sig\")\n",
    "feature_order = [f for f in rank_df.index if f in X_all.columns]\n",
    "if not feature_order:\n",
    "    raise RuntimeError(\"[Cell3D] ランキング上位特徴が存在しません。\")\n",
    "\n",
    "fair_groups = groups.astype(str).map(SUBJECT_META[\"MSSQ_group\"])\n",
    "if fair_groups.isna().any():\n",
    "    raise RuntimeError(\"[Cell3D] SUBJECT_META に存在しない subject_id があります。\")\n",
    "\n",
    "ks = list(range(len(feature_order), 0, -1))\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "def _in_group_auc(mask):\n",
    "    aucs = []\n",
    "    for k in ks:\n",
    "        feats = feature_order[:k]\n",
    "        X = X_all.loc[mask, feats].astype(np.float32)\n",
    "        y = y_all.loc[mask].values\n",
    "        g = groups.loc[mask].values\n",
    "        if len(np.unique(y)) < 2:\n",
    "            aucs.append(np.nan); continue\n",
    "        y_true_all, proba_all = [], []\n",
    "        for tr_idx, te_idx in logo.split(X, y, g):\n",
    "            X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "            y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "            if len(np.unique(y_tr)) < 2:\n",
    "                aucs.append(np.nan); break\n",
    "            model = fit_classifier(X_tr, pd.Series(y_tr))\n",
    "            proba = predict_positive_score(model, X_te)\n",
    "            y_true_all.append(y_te); proba_all.append(proba)\n",
    "        else:\n",
    "            y_true = np.concatenate(y_true_all)\n",
    "            proba = np.concatenate(proba_all)\n",
    "            aucs.append(float(roc_auc_score(y_true, proba)) if len(np.unique(y_true)) > 1 else np.nan)\n",
    "            continue\n",
    "        # breakした場合\n",
    "        if len(aucs) < len(ks):\n",
    "            aucs.extend([np.nan] * (len(ks) - len(aucs)))\n",
    "    return aucs\n",
    "\n",
    "mask_H = (fair_groups == \"High\")\n",
    "mask_L = (fair_groups == \"Low\")\n",
    "auc_high = _in_group_auc(mask_H)\n",
    "auc_low = _in_group_auc(mask_L)\n",
    "\n",
    "def _best_k(ks_list, auc_vals):\n",
    "    arr = np.asarray(auc_vals, dtype=float)\n",
    "    if np.all(~np.isfinite(arr)):\n",
    "        return None, np.nan\n",
    "    maxv = np.nanmax(arr)\n",
    "    cand = np.array(ks_list)[np.isclose(arr, maxv, rtol=1e-6, atol=1e-12)]\n",
    "    return int(np.min(cand)), float(maxv)\n",
    "\n",
    "best_k_high, best_auc_high = _best_k(ks, auc_high)\n",
    "best_k_low, best_auc_low = _best_k(ks, auc_low)\n",
    "\n",
    "with open(outpath(\"BEST_K_BY_GROUP.JSON\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"BEST_K_HIGH\": best_k_high,\n",
    "        \"BEST_AUC_HIGH\": best_auc_high,\n",
    "        \"BEST_K_LOW\": best_k_low,\n",
    "        \"BEST_AUC_LOW\": best_auc_low,\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "ax = plt.gca()\n",
    "ax.plot(ks, auc_high, marker=\"o\", label=\"MSSQ High\")\n",
    "ax.plot(ks, auc_low, marker=\"s\", label=\"MSSQ Low\")\n",
    "if best_k_high is not None:\n",
    "    ax.scatter([best_k_high], [best_auc_high], s=160, zorder=5)\n",
    "    ax.annotate(f\"High max={best_auc_high:.3f} (k={best_k_high})\",\n",
    "                xy=(best_k_high, best_auc_high),\n",
    "                xytext=(best_k_high, best_auc_high + 0.02),\n",
    "                ha=\"center\", va=\"bottom\", fontsize=18)\n",
    "if best_k_low is not None:\n",
    "    ax.scatter([best_k_low], [best_auc_low], s=160, zorder=5)\n",
    "    ax.annotate(f\"Low max={best_auc_low:.3f} (k={best_k_low})\",\n",
    "                xy=(best_k_low, best_auc_low),\n",
    "                xytext=(best_k_low, best_auc_low + 0.02),\n",
    "                ha=\"center\", va=\"bottom\", fontsize=18)\n",
    "\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel(\"Number of Features (k)\")\n",
    "ax.set_ylabel(\"ROC AUC (pooled, in-group LOSO)\")\n",
    "ax.set_title(\"AUC vs Number of Features by MSSQ Group\")\n",
    "ax.grid(True, alpha=0.4)\n",
    "ax.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(outpath(\"AUC_VS_K_BY_GROUP.PNG\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"[Cell3D] BEST_K_HIGH={best_k_high}, BEST_K_LOW={best_k_low}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f753fbc",
   "metadata": {},
   "source": [
    "# ===== Cell 4A: ROC-AUC vs k（95%信頼区間付き） =====\n",
    "# 前提: Cell3D まで実行済み（X_all, y_all, groups, SHAP_FEATURE_RANKING.CSV が存在）\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rank_df = pd.read_csv(outpath(\"SHAP_FEATURE_RANKING.CSV\"), index_col=0, encoding=\"utf-8-sig\")\n",
    "feature_order = [f for f in rank_df.index if f in X_all.columns]\n",
    "if not feature_order:\n",
    "    raise RuntimeError(\"[Cell4A] SHAPランキング上位の特徴が X_all にありません。\")\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "ks = list(range(len(feature_order), 0, -1))\n",
    "\n",
    "records = []\n",
    "for k in ks:\n",
    "    feats = feature_order[:k]\n",
    "    X = X_all[feats].astype(np.float32)\n",
    "    y = y_all.values\n",
    "    g = groups.values\n",
    "\n",
    "    y_true_all, proba_all, subj_all = [], [], []\n",
    "    for tr_idx, te_idx in logo.split(X, y, g):\n",
    "        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "        if len(np.unique(y_tr)) < 2:\n",
    "            raise RuntimeError(f\"[Cell4A] k={k}: 学習foldが単一クラスです。\")\n",
    "\n",
    "        model = fit_classifier(X_tr, pd.Series(y_tr))\n",
    "        proba = predict_positive_score(model, X_te)\n",
    "        y_true_all.append(y_te)\n",
    "        proba_all.append(proba)\n",
    "        subj_all.append(g[te_idx])\n",
    "\n",
    "    y_pool = np.concatenate(y_true_all)\n",
    "    s_pool = np.concatenate(proba_all)\n",
    "    subj_pool = np.concatenate(subj_all)\n",
    "    auc_obs = float(roc_auc_score(y_pool, s_pool))\n",
    "    records.append({\"k\": k, \"auc\": auc_obs})\n",
    "\n",
    "    # --- 被験者単位ブートストラップで95% CI ---\n",
    "    df = pd.DataFrame({\"subject\": subj_pool, \"y_true\": y_pool, \"y_score\": s_pool})\n",
    "    subj_ids = df[\"subject\"].unique()\n",
    "    B = 2000\n",
    "    rng = np.random.default_rng(20251101)\n",
    "    auc_boot = []\n",
    "    for _ in range(B):\n",
    "        sampled = rng.choice(subj_ids, size=len(subj_ids), replace=True)\n",
    "        df_boot = pd.concat([df[df[\"subject\"] == sid] for sid in sampled], ignore_index=True)\n",
    "        if df_boot[\"y_true\"].nunique() < 2:\n",
    "            continue\n",
    "        auc_boot.append(float(roc_auc_score(df_boot[\"y_true\"], df_boot[\"y_score\"])))\n",
    "    if len(auc_boot) == 0:\n",
    "        ci_low = ci_high = float(\"nan\")\n",
    "    else:\n",
    "        ci_low = float(np.quantile(auc_boot, 0.025))\n",
    "        ci_high = float(np.quantile(auc_boot, 0.975))\n",
    "    records[-1].update({\"ci_low\": ci_low, \"ci_high\": ci_high})\n",
    "\n",
    "df_auc = pd.DataFrame(records)\n",
    "df_auc.to_csv(outpath(\"AUC_K_CI.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"[Cell4A] 保存 -> {outpath('AUC_K_CI.csv')}\")\n",
    "\n",
    "# --- プロット ---\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.errorbar(df_auc[\"k\"], df_auc[\"auc\"],\n",
    "             yerr=[df_auc[\"auc\"]-df_auc[\"ci_low\"], df_auc[\"ci_high\"]-df_auc[\"auc\"]],\n",
    "             fmt='o', capsize=4, linewidth=1.2, color=\"tab:blue\")\n",
    "plt.gca().invert_xaxis()\n",
    "plt.xlabel(\"Number of features (k)\")\n",
    "plt.ylabel(\"ROC AUC (pooled)\")\n",
    "plt.title(\"ROC AUC vs k with 95% CI\")\n",
    "plt.grid(True, alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(outpath(\"AUC_K_CI.png\"), dpi=300)\n",
    "plt.close()\n",
    "print(f\"[Cell4A] 図を保存 -> {outpath('AUC_K_CI.png')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3ddca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ced576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Inner LOSO folds builder =====\n",
    "\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "def choose_inner_folds_loso(train_subject_ids: List[str]) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    外側LOSOで得た “学習側の被験者ID” リストを受け取り、\n",
    "    1名ずつ検証に回す inner-LOSO のfoldリスト（[[sid1], [sid2], ...]）を返す。\n",
    "    \"\"\"\n",
    "    if not isinstance(train_subject_ids, (list, tuple)):\n",
    "        raise RuntimeError(\"[inner folds] train_subject_ids は list/tuple を想定しています。\")\n",
    "    uniq = list(pd.unique(pd.Series([str(sid) for sid in train_subject_ids])))\n",
    "    if len(uniq) == 0:\n",
    "        raise RuntimeError(\"[inner folds] train_subject_ids が空です。\")\n",
    "    uniq_sorted = sorted(uniq, key=lambda x: (len(x), x))\n",
    "    folds = [[sid] for sid in uniq_sorted]\n",
    "    print(f\"[inner folds] {len(folds)} splits -> val subjects = {', '.join(uniq_sorted)}\")\n",
    "    return folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5A (FINAL, F1専用): inner-LOSO τ最適化（連結val）→ outer予測・評価 =====\n",
    "# 前提: Cell1〜4 実行済み（X_all, y_all, groups, SUBJECT_META, BEST_K, choose_inner_folds_loso 等）\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- 基本チェック ----------------\n",
    "req = [\"X_all\",\"y_all\",\"groups\",\"SUBJECT_META\",\n",
    "       \"choose_inner_folds_loso\",\"fit_classifier\",\"predict_positive_score\",\"outpath\"]\n",
    "missing = [v for v in req if v not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"[Cell5A] 未定義の変数/関数があります: {missing}\")\n",
    "\n",
    "if \"MSSQ_group\" not in SUBJECT_META.columns and \"MSSQ_group\" not in SUBJECT_META.index.names:\n",
    "    raise RuntimeError(\"[Cell5A] SUBJECT_META に MSSQ_group 列（または index）が必要である．\")\n",
    "\n",
    "# ---------------- 設定（等間隔グリッド＋近傍再探索） ----------------\n",
    "COARSE_STEPS = 1001      # 0.0〜1.0 を等間隔\n",
    "FINE_STEPS   = 101       # 近傍再探索の細かさ\n",
    "FINE_MARGIN  = 0.01      # 近傍幅（±0.01）\n",
    "VERBOSE      = True\n",
    "\n",
    "# ---------------- 入力整形 ----------------\n",
    "X_base = X_all.astype(np.float32)\n",
    "y_base = y_all.astype(int)\n",
    "g_base = groups.astype(str)\n",
    "\n",
    "# MSSQ group マッピング（High/Lowに正規化）\n",
    "if \"subject_id\" in SUBJECT_META.columns:\n",
    "    mapper = SUBJECT_META.set_index(\"subject_id\")[\"MSSQ_group\"].astype(str).to_dict()\n",
    "else:\n",
    "    mapper = SUBJECT_META[\"MSSQ_group\"].astype(str).to_dict()\n",
    "\n",
    "fair_groups = g_base.map(mapper).astype(str).str.strip().str.lower().map({\"high\":\"High\",\"low\":\"Low\"})\n",
    "if fair_groups.isna().any():\n",
    "    raise RuntimeError(f\"[Cell5A] MSSQ_group 未割当ID: {sorted(set(g_base[fair_groups.isna()]))}\")\n",
    "\n",
    "# 特徴選抜（SHAP順の上位K）\n",
    "rank_df = pd.read_csv(outpath(\"SHAP_FEATURE_RANKING.CSV\"), index_col=0, encoding=\"utf-8-sig\")\n",
    "feature_order = [f for f in rank_df.index if f in X_base.columns]\n",
    "feats_k = feature_order[:best_k]\n",
    "if len(feats_k) < best_k:\n",
    "    print(f\"[Cell5A][WARN] ランキング上位に X に無い特徴が混在 → {len(feats_k)} 列で実行．\")\n",
    "X_k = X_base[feats_k]\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"[DBG] 使用特徴数: {len(feats_k)}  (BEST_K={best_k})\")\n",
    "\n",
    "# ---------------- 指標・評価ユーティリティ（F1専用） ----------------\n",
    "def _conf_from_preds(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    TN, FP, FN, TP = skm.confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    return TP, FP, FN, TN\n",
    "\n",
    "def _f1_from_conf(TP, FP, FN, TN) -> float:\n",
    "    TP = float(TP); FP = float(FP); FN = float(FN)\n",
    "    denom = (2*TP + FP + FN)\n",
    "    return (2*TP / denom) if denom > 0 else 0.0\n",
    "\n",
    "def _f1_binary(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    TP, FP, FN, TN = _conf_from_preds(y_true, y_pred)\n",
    "    return _f1_from_conf(TP, FP, FN, TN)\n",
    "\n",
    "def _grid(l, r, steps):\n",
    "    l = float(max(0.0, l)); r = float(min(1.0, r))\n",
    "    if l > r: l, r = r, l\n",
    "    return np.linspace(l, r, int(steps), dtype=float)\n",
    "\n",
    "# ---------------- τ最適化（Single / WG-F1 / Group-F1） ----------------\n",
    "def _single_tau_opt(scores: np.ndarray, y: np.ndarray):\n",
    "    # coarse\n",
    "    cands = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "    f1_vec = []\n",
    "    for t in cands:\n",
    "        yhat = (scores >= t).astype(int)\n",
    "        f1_vec.append(_f1_binary(y, yhat))\n",
    "    f1_vec = np.asarray(f1_vec)\n",
    "    idx = int(np.nanargmax(f1_vec)); tau0 = float(cands[idx]); best0 = float(f1_vec[idx])\n",
    "\n",
    "    # fine around tau0\n",
    "    left  = max(0.0, tau0 - FINE_MARGIN)\n",
    "    right = min(1.0, tau0 + FINE_MARGIN)\n",
    "    cands2 = _grid(left, right, FINE_STEPS)\n",
    "    f1_vec2 = []\n",
    "    for t in cands2:\n",
    "        yhat = (scores >= t).astype(int)\n",
    "        f1_vec2.append(_f1_binary(y, yhat))\n",
    "    f1_vec2 = np.asarray(f1_vec2)\n",
    "    idx2 = int(np.nanargmax(f1_vec2)); tau = float(cands2[idx2]); best = float(f1_vec2[idx2])\n",
    "\n",
    "    return {\"tau\": tau, \"F1_val\": best, \"tau_coarse\": tau0, \"F1_coarse\": best0}\n",
    "\n",
    "def _wg_f1_opt_joint(scores: np.ndarray, y: np.ndarray, grp: np.ndarray):\n",
    "    \"\"\"\n",
    "    Fair-MinF1（最悪群F1の最大化）を 2Dグリッド（τH×τL）で探索する．\n",
    "    戻り値:\n",
    "      {\"tauH\",\"tauL\",\"F1_H_val\",\"F1_L_val\",\"WG_F1_val\",\"F1_pooled_val\"}\n",
    "    \"\"\"\n",
    "    maskH = (grp == \"High\"); maskL = (grp == \"Low\")\n",
    "    if (maskH.sum()==0) or (maskL.sum()==0):\n",
    "        raise RuntimeError(\"[WG-F1] 連結valに High/Low の両群が必要（どちらかが0件）\")\n",
    "\n",
    "    sH, yH = scores[maskH], y[maskH]\n",
    "    sL, yL = scores[maskL], y[maskL]\n",
    "\n",
    "    candH = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "    candL = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "\n",
    "    def _f1_vec(s, yy, cands):\n",
    "        f1 = np.empty_like(cands)\n",
    "        for i, t in enumerate(cands):\n",
    "            yhat = (s >= t).astype(int)\n",
    "            f1[i] = _f1_binary(yy, yhat)\n",
    "        return f1\n",
    "\n",
    "    f1H = _f1_vec(sH, yH, candH)\n",
    "    f1L = _f1_vec(sL, yL, candL)\n",
    "\n",
    "    best = {\"WG\": -np.inf, \"pooled\": -np.inf, \"tH\": 0.5, \"tL\": 0.5, \"F1H\": 0.0, \"F1L\": 0.0}\n",
    "    for i, tH in enumerate(candH):\n",
    "        wg_row = np.minimum(f1H[i], f1L)\n",
    "        j = int(np.nanargmax(wg_row))\n",
    "        WG = float(wg_row[j])\n",
    "\n",
    "        yhatH = (sH >= tH).astype(int)\n",
    "        yhatL = (sL >= candL[j]).astype(int)\n",
    "        F1_pooled = _f1_binary(\n",
    "            np.concatenate([yH, yL]),\n",
    "            np.concatenate([yhatH, yhatL])\n",
    "        )\n",
    "\n",
    "        cand = {\"WG\": WG, \"pooled\": float(F1_pooled),\n",
    "                \"tH\": float(tH), \"tL\": float(candL[j]),\n",
    "                \"F1H\": float(f1H[i]), \"F1L\": float(f1L[j])}\n",
    "\n",
    "        def _is_better(cur, new):\n",
    "            if new[\"WG\"] > cur[\"WG\"]: return True\n",
    "            if new[\"WG\"] < cur[\"WG\"]: return False\n",
    "            if new[\"pooled\"] > cur[\"pooled\"]: return True\n",
    "            if new[\"pooled\"] < cur[\"pooled\"]: return False\n",
    "            if abs(new[\"tH\"]-new[\"tL\"]) < abs(cur[\"tH\"]-cur[\"tL\"]): return True\n",
    "            if abs(new[\"tH\"]-new[\"tL\"]) > abs(cur[\"tH\"]-cur[\"tL\"]): return False\n",
    "            if (new[\"tH\"], new[\"tL\"]) < (cur[\"tH\"], cur[\"tL\"]): return True\n",
    "            return False\n",
    "\n",
    "        if _is_better(best, cand):\n",
    "            best = cand\n",
    "\n",
    "    # fine (box refine)\n",
    "    lH = max(0.0, best[\"tH\"] - FINE_MARGIN); rH = min(1.0, best[\"tH\"] + FINE_MARGIN)\n",
    "    lL = max(0.0, best[\"tL\"] - FINE_MARGIN); rL = min(1.0, best[\"tL\"] + FINE_MARGIN)\n",
    "    candH2 = _grid(lH, rH, FINE_STEPS)\n",
    "    candL2 = _grid(lL, rL, FINE_STEPS)\n",
    "\n",
    "    f1H2 = _f1_vec(sH, yH, candH2)\n",
    "    f1L2 = _f1_vec(sL, yL, candL2)\n",
    "\n",
    "    best2 = dict(best)\n",
    "    for i, tH in enumerate(candH2):\n",
    "        wg_row = np.minimum(f1H2[i], f1L2)\n",
    "        j = int(np.nanargmax(wg_row))\n",
    "        WG = float(wg_row[j])\n",
    "\n",
    "        yhatH = (sH >= tH).astype(int)\n",
    "        yhatL = (sL >= candL2[j]).astype(int)\n",
    "        F1_pooled = _f1_binary(\n",
    "            np.concatenate([yH, yL]),\n",
    "            np.concatenate([yhatH, yhatL])\n",
    "        )\n",
    "        cand = {\"WG\": WG, \"pooled\": float(F1_pooled),\n",
    "                \"tH\": float(tH), \"tL\": float(candL2[j]),\n",
    "                \"F1H\": float(f1H2[i]), \"F1L\": float(f1L2[j])}\n",
    "\n",
    "        if (cand[\"WG\"] > best2[\"WG\"] or\n",
    "            (cand[\"WG\"] == best2[\"WG\"] and (\n",
    "                cand[\"pooled\"] > best2[\"pooled\"] or\n",
    "                (cand[\"pooled\"] == best2[\"pooled\"] and (\n",
    "                    abs(cand[\"tH\"]-cand[\"tL\"]) < abs(best2[\"tH\"]-best2[\"tL\"]) or\n",
    "                    (abs(cand[\"tH\"]-cand[\"tL\"]) == abs(best2[\"tH\"]-best2[\"tL\"]) and\n",
    "                     (cand[\"tH\"], cand[\"tL\"]) < (best2[\"tH\"], best2[\"tL\"]))\n",
    "                ))\n",
    "            ))):\n",
    "            best2 = cand\n",
    "\n",
    "    return {\n",
    "        \"tauH\": best2[\"tH\"], \"tauL\": best2[\"tL\"],\n",
    "        \"F1_H_val\": best2[\"F1H\"], \"F1_L_val\": best2[\"F1L\"],\n",
    "        \"WG_F1_val\": best2[\"WG\"], \"F1_pooled_val\": best2[\"pooled\"],\n",
    "    }\n",
    "\n",
    "def _group_f1_opt(scores: np.ndarray, y: np.ndarray, grp: np.ndarray):\n",
    "    # 2Dグリッド（τH×τL）で pooled F1 最大化（coarse→fine）\n",
    "    maskH = (grp == \"High\"); maskL = (grp == \"Low\")\n",
    "    if (maskH.sum()==0) or (maskL.sum()==0):\n",
    "        raise RuntimeError(\"[Group-F1] 連結valに High/Low の両群が必要（どちらかが0件）\")\n",
    "\n",
    "    sH, yH = scores[maskH], y[maskH]\n",
    "    sL, yL = scores[maskL], y[maskL]\n",
    "\n",
    "    def _pooled_f1_for(tH, tL):\n",
    "        yhatH = (sH >= tH).astype(int)\n",
    "        yhatL = (sL >= tL).astype(int)\n",
    "        y_true = np.concatenate([yH, yL])\n",
    "        y_pred = np.concatenate([yhatH, yhatL])\n",
    "        return _f1_binary(y_true, y_pred)\n",
    "\n",
    "    candH = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "    candL = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "    best = {\"F1_val\": -np.inf, \"tauH\": None, \"tauL\": None}\n",
    "    for tH in candH:\n",
    "        f1_vec = np.empty_like(candL)\n",
    "        for j, tL in enumerate(candL):\n",
    "            f1_vec[j] = _pooled_f1_for(tH, tL)\n",
    "        jmax = int(np.nanargmax(f1_vec))\n",
    "        if float(f1_vec[jmax]) > best[\"F1_val\"]:\n",
    "            best.update({\"F1_val\": float(f1_vec[jmax]), \"tauH\": float(tH), \"tauL\": float(candL[jmax])})\n",
    "\n",
    "    # fine\n",
    "    lH = max(0.0, best[\"tauH\"] - FINE_MARGIN); rH = min(1.0, best[\"tauH\"] + FINE_MARGIN)\n",
    "    lL = max(0.0, best[\"tauL\"] - FINE_MARGIN); rL = min(1.0, best[\"tauL\"] + FINE_MARGIN)\n",
    "    candH2 = _grid(lH, rH, FINE_STEPS); candL2 = _grid(lL, rL, FINE_STEPS)\n",
    "\n",
    "    best2 = dict(best)\n",
    "    for tH in candH2:\n",
    "        f1_vec2 = np.empty_like(candL2)\n",
    "        for j, tL in enumerate(candL2):\n",
    "            f1_vec2[j] = _pooled_f1_for(tH, tL)\n",
    "        jmax = int(np.nanargmax(f1_vec2))\n",
    "        if float(f1_vec2[jmax]) > best2[\"F1_val\"]:\n",
    "            best2.update({\"F1_val\": float(f1_vec2[jmax]), \"tauH\": float(tH), \"tauL\": float(candL2[jmax])})\n",
    "\n",
    "    return best2  # {\"tauH\",\"tauL\",\"F1_val\"}\n",
    "\n",
    "# ---------------- outer LOSO with inner concatenation ----------------\n",
    "logo_outer = LeaveOneGroupOut()\n",
    "rows, pred_rows = [], []\n",
    "\n",
    "for fold_id, (tr_idx, te_idx) in enumerate(logo_outer.split(X_k, y_base.values, g_base.values), start=1):\n",
    "    train_mask = pd.Series(False, index=g_base.index); train_mask.iloc[tr_idx] = True\n",
    "    test_mask  = pd.Series(False, index=g_base.index);  test_mask.iloc[te_idx]  = True\n",
    "    test_sid = g_base.iloc[te_idx].iloc[0]\n",
    "\n",
    "    # ===== inner folds =====\n",
    "    inner_ids   = sorted(g_base[train_mask].unique())\n",
    "    inner_folds = choose_inner_folds_loso(inner_ids)\n",
    "    if VERBOSE:\n",
    "        print(f\"[inner folds] {len(inner_folds)} splits -> val subjects = {', '.join(inner_ids)}\")\n",
    "\n",
    "    # 連結valの器\n",
    "    val_scores_all, val_y_all, val_grp_all = [], [], []\n",
    "\n",
    "    # --- inner train に両群が居るか（群別τの前提） ---\n",
    "    inner_train_groups = fair_groups[train_mask]\n",
    "    if not ((\"High\" in set(inner_train_groups)) and (\"Low\" in set(inner_train_groups))):\n",
    "        raise RuntimeError(f\"[Cell5A] fold{fold_id}: inner-train に両群(High/Low)が必要（群別τの前提）\")\n",
    "\n",
    "    # ===== inner: train→val 予測の連結 =====\n",
    "    for inner_val in inner_folds:\n",
    "        val_mask  = g_base.isin(inner_val) & train_mask\n",
    "        trn_mask  = train_mask & (~val_mask)\n",
    "        if not trn_mask.any() or not val_mask.any():\n",
    "            continue\n",
    "\n",
    "        X_tr, y_tr = X_k[trn_mask], y_base[trn_mask]\n",
    "        X_vl, y_vl = X_k[val_mask], y_base[val_mask]\n",
    "        grp_vl     = fair_groups[val_mask].to_numpy()\n",
    "\n",
    "        # inner 学習\n",
    "        model_inner = fit_classifier(X_tr, y_tr)\n",
    "        sc_vl = predict_positive_score(model_inner, X_vl).astype(float)\n",
    "\n",
    "        # 連結（生の val 予測）\n",
    "        val_scores_all.append(sc_vl)\n",
    "        val_y_all.append(y_vl.to_numpy())\n",
    "        val_grp_all.append(grp_vl)\n",
    "\n",
    "        if VERBOSE:\n",
    "            nH = int((grp_vl==\"High\").sum()); nL = int((grp_vl==\"Low\").sum())\n",
    "            print(f\"[DBG] fold{fold_id}: inner_val size={len(y_vl):3d}  High={nH} Low={nL}\")\n",
    "\n",
    "    # 連結\n",
    "    if len(val_scores_all) == 0:\n",
    "        raise RuntimeError(f\"[Cell5A] fold{fold_id}: inner validation が空である．\")\n",
    "    s_val = np.concatenate(val_scores_all)\n",
    "    y_val = np.concatenate(val_y_all)\n",
    "    g_val = np.concatenate(val_grp_all)\n",
    "\n",
    "    # ===== 連結valで一度だけ τ を最適化（F1） =====\n",
    "    res_single = _single_tau_opt(s_val, y_val)\n",
    "    tau_single = float(res_single[\"tau\"])\n",
    "\n",
    "    res_wg = _wg_f1_opt_joint(s_val, y_val, g_val)\n",
    "    tauH_wg, tauL_wg = float(res_wg[\"tauH\"]), float(res_wg[\"tauL\"])\n",
    "\n",
    "    res_group = _group_f1_opt(s_val, y_val, g_val)\n",
    "    tauH_grp, tauL_grp = float(res_group[\"tauH\"]), float(res_group[\"tauL\"])\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"[DBG] fold{fold_id}: tau_single={tau_single:.6f} | \"\n",
    "              f\"Group-F1(tH,tL)=({tauH_grp:.6f},{tauL_grp:.6f}) | \"\n",
    "              f\"WG-F1(tH,tL)=({tauH_wg:.6f},{tauL_wg:.6f})\")\n",
    "\n",
    "    # ===== outer test =====\n",
    "    X_tr_o, y_tr_o = X_k[train_mask], y_base[train_mask]\n",
    "    X_te_o, y_te_o = X_k[test_mask],  y_base[test_mask]\n",
    "    grp_te         = fair_groups[test_mask].to_numpy()\n",
    "\n",
    "    model_outer = fit_classifier(X_tr_o, y_tr_o)\n",
    "    sc_te = predict_positive_score(model_outer, X_te_o).astype(float)\n",
    "\n",
    "    yhat_single = (sc_te >= tau_single).astype(int)\n",
    "    yhat_groupF1 = (sc_te >= np.where(grp_te==\"High\", tauH_grp, tauL_grp)).astype(int)\n",
    "    yhat_wgF1    = (sc_te >= np.where(grp_te==\"High\", tauH_wg,  tauL_wg )).astype(int)\n",
    "\n",
    "    F1_single = _f1_binary(y_te_o.to_numpy(), yhat_single)\n",
    "    F1_group  = _f1_binary(y_te_o.to_numpy(), yhat_groupF1)\n",
    "    F1_wg     = _f1_binary(y_te_o.to_numpy(), yhat_wgF1)\n",
    "\n",
    "    if VERBOSE:\n",
    "        same_grp = bool(np.array_equal(yhat_single, yhat_groupF1))\n",
    "        same_wg  = bool(np.array_equal(yhat_single, yhat_wgF1))\n",
    "        nH_te = int((grp_te==\"High\").sum()); nL_te = int((grp_te==\"Low\").sum())\n",
    "        print(f\"[DBG] fold{fold_id}: TEST High={nH_te} Low={nL_te} | \"\n",
    "              f\"Single==Group-F1: {same_grp}  Single==WG-F1: {same_wg} | \"\n",
    "              f\"F1(single, group, wg)=({F1_single:.3f}, {F1_group:.3f}, {F1_wg:.3f})\")\n",
    "\n",
    "    rows.append({\n",
    "        \"fold_id\": int(fold_id),\n",
    "        \"test_id\": str(test_sid),\n",
    "        \"best_k\": int(best_k),\n",
    "        \"tau_single\": float(tau_single),\n",
    "        \"tau_high_GroupF1\": float(tauH_grp), \"tau_low_GroupF1\": float(tauL_grp),\n",
    "        \"tau_high_WGF1\": float(tauH_wg),     \"tau_low_WGF1\": float(tauL_wg),\n",
    "        \"F1_single\": float(F1_single),\n",
    "        \"F1_group\":  float(F1_group),\n",
    "        \"F1_group_WG\": float(F1_wg),\n",
    "        \"n_test\": int(len(y_te_o)),\n",
    "    })\n",
    "\n",
    "    # 予測詳細（F1専用命名）\n",
    "    for yy, ss, gg, ys, yg, yw in zip(y_te_o, sc_te, grp_te, yhat_single, yhat_groupF1, yhat_wgF1):\n",
    "        pred_rows.append({\n",
    "            \"fold_id\": int(fold_id),\n",
    "            \"test_id\": str(test_sid),\n",
    "            \"y_true\": int(yy),\n",
    "            \"proba\": float(ss),\n",
    "            \"group\": str(gg),\n",
    "            \"y_pred_single\": int(ys),\n",
    "            \"y_pred_group_F1\": int(yg),\n",
    "            \"y_pred_group_WG\": int(yw),\n",
    "        })\n",
    "    \n",
    "    print(f\"[DBG] fold{fold_id}: WG-joint val -> \"\n",
    "          f\"F1_H={res_wg['F1_H_val']:.3f}, F1_L={res_wg['F1_L_val']:.3f}, \"\n",
    "          f\"WG(F1)={res_wg['WG_F1_val']:.3f}, pooled(F1)={res_wg['F1_pooled_val']:.3f}, \"\n",
    "          f\"(tH,tL)=({tauH_wg:.4f},{tauL_wg:.4f})\")\n",
    "\n",
    "# ---------------- 出力 ----------------\n",
    "df_fold = pd.DataFrame(rows)\n",
    "df_pred = pd.DataFrame(pred_rows)\n",
    "df_fold.to_csv(outpath(\"GROUP_AWARE_THRESH_BY_FOLD.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "df_pred.to_csv(outpath(\"GROUP_AWARE_PREDICTIONS.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 参考: プールAUC（確率は共通なので1つ）\n",
    "auc_pool = float(roc_auc_score(df_pred[\"y_true\"].to_numpy(), df_pred[\"proba\"].to_numpy()))\n",
    "\n",
    "def _pooled_f1(col):\n",
    "    y_true = df_pred[\"y_true\"].to_numpy()\n",
    "    yhat   = df_pred[col].to_numpy().astype(int)\n",
    "    return _f1_binary(y_true, yhat)\n",
    "\n",
    "summary = {\n",
    "    \"best_k\": int(best_k),\n",
    "    \"AUC_pooled\": auc_pool,  # 不要ならこのキーごと削除可\n",
    "    \"F1_pooled_single\": _pooled_f1(\"y_pred_single\"),\n",
    "    \"F1_pooled_group\":  _pooled_f1(\"y_pred_group_F1\"),\n",
    "    \"F1_pooled_group_WG\": _pooled_f1(\"y_pred_group_WG\"),\n",
    "    \"metric\": \"F1\",\n",
    "    \"n_samples\": int(len(df_pred)),\n",
    "    \"n_pos\": int((df_pred[\"y_true\"]==1).sum()),\n",
    "    \"n_neg\": int((df_pred[\"y_true\"]==0).sum()),\n",
    "}\n",
    "pd.DataFrame([summary]).to_csv(outpath(\"GROUP_AWARE_SUMMARY.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"[Cell5A] Done: outer folds={len(df_fold)}, pooled AUC={auc_pool:.3f}\")\n",
    "print(f\"[Cell5A] Summary: {summary}\")\n",
    "\n",
    "# ---------------- 混同行列プロット（F1専用ラベル） ----------------\n",
    "def _draw_cm(cm, title, path):\n",
    "    fig, ax = plt.subplots(figsize=(7,6))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\", vmin=0, vmax=max(cm.max(),1))\n",
    "    labels = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            val = int(cm[i,j])\n",
    "            color = \"white\" if val > 0.6*im.get_clim()[1] else \"black\"\n",
    "            ax.text(j, i, f\"{labels[i,j]}\\n{val}\", ha=\"center\", va=\"center\",\n",
    "                    fontsize=18, fontweight=\"bold\", color=color)\n",
    "    ax.set_xticks([0,1]); ax.set_xticklabels([\"Pred:0\",\"Pred:1\"])\n",
    "    ax.set_yticks([0,1]); ax.set_yticklabels([\"True:0\",\"True:1\"], rotation=90, va=\"center\")\n",
    "    ax.set_title(title); ax.grid(False)\n",
    "    plt.tight_layout(); plt.savefig(path, dpi=300); plt.close()\n",
    "\n",
    "y_pool = df_pred[\"y_true\"].to_numpy()\n",
    "cm_single = skm.confusion_matrix(y_pool, df_pred[\"y_pred_single\"],    labels=[0,1])\n",
    "cm_group  = skm.confusion_matrix(y_pool, df_pred[\"y_pred_group_F1\"],  labels=[0,1])\n",
    "cm_wg     = skm.confusion_matrix(y_pool, df_pred[\"y_pred_group_WG\"],  labels=[0,1])\n",
    "\n",
    "_draw_cm(cm_single, f\"Cell5A Single τ (F1={summary['F1_pooled_single']:.3f})\",\n",
    "         outpath(\"CONFMAT_CELL5A_SINGLE(F1).png\"))\n",
    "_draw_cm(cm_group,  f\"Cell5A Group-F1 τ (F1={summary['F1_pooled_group']:.3f})\",\n",
    "         outpath(\"CONFMAT_CELL5A_GROUP(F1).png\"))\n",
    "_draw_cm(cm_wg,     f\"Cell5A WG-F1 τ (F1={summary['F1_pooled_group_WG']:.3f})\",\n",
    "         outpath(\"CONFMAT_CELL5A_WG(F1).png\"))\n",
    "print(\"[Cell5A] Confusion matrices saved -> CONFMAT_CELL5A_*.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5B++: 確率スコア分布（OVERALL/群別/各Fold）＋ τ の中央値/IQR 帯・±表記 =====\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- 設定 ----------\n",
    "BINS = 40\n",
    "LW = 1.5\n",
    "FS_TITLE, FS_LABEL, FS_LEGEND, FS_TICK = 30, 24, 20, 20\n",
    "\n",
    "# 色指定（ユーザ指定）\n",
    "COLOR_SICK = \"red\"   # True:Sick\n",
    "COLOR_NON  = \"blue\"  # True:Non-Sick\n",
    "\n",
    "# 線色（しきい値）\n",
    "COLOR_SINGLE = \"black\"\n",
    "COLOR_GROUP  = \"green\"\n",
    "COLOR_WG     = \"purple\"\n",
    "\n",
    "# 出力フォルダ（新規作成）\n",
    "RUN_ROOT = os.path.dirname(outpath(\"__dummy__\"))\n",
    "IMG_DIR  = os.path.join(RUN_ROOT, \"PROBA_DIST_F1\")\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "# ファイルパス\n",
    "SAVE_OVERALL_SvG   = os.path.join(IMG_DIR, \"OVERALL_SvGroup.png\")\n",
    "SAVE_OVERALL_SvWG  = os.path.join(IMG_DIR, \"OVERALL_SvWG.png\")\n",
    "SAVE_BYGROUP_SvG   = os.path.join(IMG_DIR, \"BYGROUP_SvGroup.png\")\n",
    "SAVE_BYGROUP_SvWG  = os.path.join(IMG_DIR, \"BYGROUP_SvWG.png\")\n",
    "\n",
    "# ---------- 入力 ----------\n",
    "pred_path = outpath(\"GROUP_AWARE_PREDICTIONS.CSV\")\n",
    "fold_path = outpath(\"GROUP_AWARE_THRESH_BY_FOLD.CSV\")\n",
    "if not (os.path.exists(pred_path) and os.path.exists(fold_path)):\n",
    "    raise FileNotFoundError(\"[Cell5B++] 必要CSVが見つからない（Cell 5A を先に実行）\")\n",
    "\n",
    "df_pred = pd.read_csv(pred_path, encoding=\"utf-8-sig\")\n",
    "df_fold = pd.read_csv(fold_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# ---------- モード自動判定（F1 or BA） ----------\n",
    "cols_f1 = {\"high\":\"tau_high_GroupF1\", \"low\":\"tau_low_GroupF1\", \"wgh\":\"tau_high_WGF1\", \"wgl\":\"tau_low_WGF1\"}\n",
    "cols_ba = {\"high\":\"tau_high_GroupBA\", \"low\":\"tau_low_GroupBA\", \"wgh\":\"tau_high_WGBA\", \"wgl\":\"tau_low_WGBA\"}\n",
    "\n",
    "if all(c in df_fold.columns for c in [cols_f1[\"high\"], cols_f1[\"low\"]]):\n",
    "    mode = \"F1\"\n",
    "    c_high, c_low, c_wgh, c_wgl = cols_f1[\"high\"], cols_f1[\"low\"], cols_f1[\"wgh\"], cols_f1[\"wgl\"]\n",
    "    pred_group_col = \"y_pred_group_F1\"\n",
    "elif all(c in df_fold.columns for c in [cols_ba[\"high\"], cols_ba[\"low\"]]):\n",
    "    mode = \"BA\"\n",
    "    c_high, c_low, c_wgh, c_wgl = cols_ba[\"high\"], cols_ba[\"low\"], cols_ba[\"wgh\"], cols_ba[\"wgl\"]\n",
    "    pred_group_col = \"y_pred_group_BA\"\n",
    "else:\n",
    "    raise RuntimeError(\"[Cell5B++] しきい値列が見つからない（F1/BAどちらかのCell 5Aの出力が必要）\")\n",
    "\n",
    "# ---------- 集約: 中央値/IQR（Q1〜Q3） ----------\n",
    "def _qstats(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    s = s[np.isfinite(s)]\n",
    "    if s.size == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan  # med, q1, q3, half_iqr\n",
    "    med = float(np.nanmedian(s))\n",
    "    q1, q3 = np.nanpercentile(s, [25, 75])\n",
    "    half = float((q3 - q1)/2.0)\n",
    "    return float(med), float(q1), float(q3), half\n",
    "\n",
    "tau_single_med, tau_single_q1, tau_single_q3, tau_single_half = _qstats(df_fold[\"tau_single\"])\n",
    "tau_high_med,   tau_high_q1,   tau_high_q3,   tau_high_half   = _qstats(df_fold[c_high])\n",
    "tau_low_med,    tau_low_q1,    tau_low_q3,    tau_low_half    = _qstats(df_fold[c_low])\n",
    "tau_high_wg,    tau_high_wg_q1, tau_high_wg_q3, tau_high_wg_half = _qstats(df_fold[c_wgh]) if c_wgh in df_fold.columns else (np.nan, np.nan, np.nan, np.nan)\n",
    "tau_low_wg,     tau_low_wg_q1,  tau_low_wg_q3,  tau_low_wg_half  = _qstats(df_fold[c_wgl]) if c_wgl in df_fold.columns else (np.nan, np.nan, np.nan, np.nan)\n",
    "\n",
    "# ---------- データ分解 ----------\n",
    "proba = pd.to_numeric(df_pred[\"proba\"], errors=\"coerce\").values\n",
    "ytrue = pd.to_numeric(df_pred[\"y_true\"], errors=\"coerce\").values.astype(int)\n",
    "grp   = df_pred[\"group\"].astype(str).str.strip()\n",
    "\n",
    "p_sick = proba[ytrue == 1]   # True:Sick\n",
    "p_non  = proba[ytrue == 0]   # True:Non-Sick\n",
    "n_sick, n_non = len(p_sick), len(p_non)\n",
    "\n",
    "maskH = (grp == \"High\"); maskL = (grp == \"Low\")\n",
    "\n",
    "# ---------- ユーティリティ ----------\n",
    "def _style_axes(ax, title=None):\n",
    "    if title: ax.set_title(title, fontsize=FS_TITLE)\n",
    "    ax.set_xlabel(\"Predicted probability\", fontsize=FS_LABEL)\n",
    "    ax.set_ylabel(\"Density\", fontsize=FS_LABEL)\n",
    "    ax.tick_params(axis=\"both\", labelsize=FS_TICK)\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "def _hist_overall(ax):\n",
    "    ax.hist(p_sick, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={n_sick})\", color=COLOR_SICK)\n",
    "    ax.hist(p_non,  bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={n_non})\", color=COLOR_NON)\n",
    "\n",
    "def _hist_bygroup(axes):\n",
    "    # High\n",
    "    p_sick_H = proba[(ytrue==1) & maskH]; p_non_H = proba[(ytrue==0) & maskH]\n",
    "    axes[0].hist(p_sick_H, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={len(p_sick_H)})\", color=COLOR_SICK)\n",
    "    axes[0].hist(p_non_H,  bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={len(p_non_H)})\", color=COLOR_NON)\n",
    "    _style_axes(axes[0], \"High group\")\n",
    "    # Low\n",
    "    p_sick_L = proba[(ytrue==1) & maskL]; p_non_L = proba[(ytrue==0) & maskL]\n",
    "    axes[1].hist(p_sick_L, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={len(p_sick_L)})\", color=COLOR_SICK)\n",
    "    axes[1].hist(p_non_L,  bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={len(p_non_L)})\", color=COLOR_NON)\n",
    "    _style_axes(axes[1], \"Low group\")\n",
    "\n",
    "def _vline_with_iqr(ax, x_med, q1, q3, color, ls, label_core):\n",
    "    if np.isfinite(x_med):\n",
    "        ax.axvline(x_med, color=color, linestyle=ls, linewidth=LW,\n",
    "                   label=f\"{label_core} = {x_med:.3f} ± {(q3-q1)/2:.3f}\" if (np.isfinite(q1) and np.isfinite(q3)) else f\"{label_core} = {x_med:.3f}\")\n",
    "    if np.isfinite(q1) and np.isfinite(q3):\n",
    "        ax.axvspan(q1, q3, color=color, alpha=0.12)\n",
    "\n",
    "# ---------- 1) OVERALL: Single vs Group（中央値・IQR帯・±表記） ----------\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "_hist_overall(ax)\n",
    "_vline_with_iqr(ax, tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(ax, tau_high_med,   tau_high_q1,   tau_high_q3,   COLOR_GROUP,  \"--\", f\"τ_high_{mode}\")\n",
    "_vline_with_iqr(ax, tau_low_med,    tau_low_q1,    tau_low_q3,    COLOR_GROUP,  \"--\", f\"τ_low_{mode}\")\n",
    "_style_axes(ax, title=f\"Probability distribution (OVERALL) — Single vs Group [{mode}]\")\n",
    "ax.legend(fontsize=FS_LEGEND)\n",
    "plt.tight_layout(); plt.savefig(SAVE_OVERALL_SvG, dpi=300); plt.close()\n",
    "print(f\"[Cell5B++] Saved -> {SAVE_OVERALL_SvG}\")\n",
    "\n",
    "# ---------- 2) OVERALL: Single vs WG（中央値・IQR帯・±表記） ----------\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "_hist_overall(ax)\n",
    "_vline_with_iqr(ax, tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(ax, tau_high_wg,    tau_high_wg_q1, tau_high_wg_q3, COLOR_WG, \":\", \"τ_high_WG\")\n",
    "_vline_with_iqr(ax, tau_low_wg,     tau_low_wg_q1,  tau_low_wg_q3,  COLOR_WG, \":\", \"τ_low_WG\")\n",
    "_style_axes(ax, title=f\"Probability distribution (OVERALL) — Single vs WG [{mode}]\")\n",
    "ax.legend(fontsize=FS_LEGEND)\n",
    "plt.tight_layout(); plt.savefig(SAVE_OVERALL_SvWG, dpi=300); plt.close()\n",
    "print(f\"[Cell5B++] Saved -> {SAVE_OVERALL_SvWG}\")\n",
    "\n",
    "# ---------- 3) BY_GROUP: Single vs Group（各群パネルに該当の IQR帯） ----------\n",
    "fig, axes = plt.subplots(2, 1, figsize=(9,10), sharex=True)\n",
    "_hist_bygroup(axes)\n",
    "# Single は両段に表示\n",
    "_vline_with_iqr(axes[0], tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(axes[1], tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "# High 段に High の Group τ、Low 段に Low の Group τ\n",
    "_vline_with_iqr(axes[0], tau_high_med, tau_high_q1, tau_high_q3, COLOR_GROUP, \"--\", f\"τ_high_{mode}\")\n",
    "_vline_with_iqr(axes[1], tau_low_med,  tau_low_q1,  tau_low_q3,  COLOR_GROUP, \"--\", f\"τ_low_{mode}\")\n",
    "axes[0].legend(fontsize=FS_LEGEND); axes[1].legend(fontsize=FS_LEGEND)\n",
    "plt.tight_layout(); plt.savefig(SAVE_BYGROUP_SvG, dpi=300); plt.close()\n",
    "print(f\"[Cell5B++] Saved -> {SAVE_BYGROUP_SvG}\")\n",
    "\n",
    "# ---------- 4) BY_GROUP: Single vs WG（各群パネルに該当の IQR帯） ----------\n",
    "fig, axes = plt.subplots(2, 1, figsize=(9,10), sharex=True)\n",
    "_hist_bygroup(axes)\n",
    "_vline_with_iqr(axes[0], tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(axes[1], tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(axes[0], tau_high_wg, tau_high_wg_q1, tau_high_wg_q3, COLOR_WG, \":\", \"τ_high_WG\")\n",
    "_vline_with_iqr(axes[1], tau_low_wg,  tau_low_wg_q1,  tau_low_wg_q3,  COLOR_WG, \":\", \"τ_low_WG\")\n",
    "axes[0].legend(fontsize=FS_LEGEND); axes[1].legend(fontsize=FS_LEGEND)\n",
    "plt.tight_layout(); plt.savefig(SAVE_BYGROUP_SvWG, dpi=300); plt.close()\n",
    "print(f\"[Cell5B++] Saved -> {SAVE_BYGROUP_SvWG}\")\n",
    "\n",
    "# ---------- 5) Fold単位：OVERALL の確率分布と各Foldの τ（Single vs Group / Single vs WG） ----------\n",
    "#   - 各Foldのテストサンプルのみでヒストを作図\n",
    "#   - しきい値は「そのFold行」の値を直接表示（±は不要／IQR帯は使わない）\n",
    "for _, row in df_fold.iterrows():\n",
    "    fid = int(row[\"fold_id\"]) if \"fold_id\" in row else None\n",
    "    test_id = str(row.get(\"test_id\", f\"fold{fid}\"))\n",
    "    sub = df_pred[df_pred[\"fold_id\"] == fid] if \"fold_id\" in df_pred.columns and fid is not None else df_pred.copy()\n",
    "\n",
    "    p = pd.to_numeric(sub[\"proba\"], errors=\"coerce\").values\n",
    "    yt = pd.to_numeric(sub[\"y_true\"], errors=\"coerce\").values.astype(int)\n",
    "    p_s, p_n = p[yt==1], p[yt==0]\n",
    "\n",
    "    # 値（このFoldの τ）\n",
    "    t_single = float(row[\"tau_single\"])\n",
    "    t_high   = float(row[c_high]) if c_high in row else np.nan\n",
    "    t_low    = float(row[c_low])  if c_low  in row else np.nan\n",
    "    t_high_w = float(row[c_wgh])  if c_wgh  in row else np.nan\n",
    "    t_low_w  = float(row[c_wgl])  if c_wgl  in row else np.nan\n",
    "\n",
    "    # 出力パス\n",
    "    p_sg  = os.path.join(IMG_DIR, f\"FOLD{fid:02d}_{test_id}_OVERALL_SvGroup.png\")\n",
    "    p_wg  = os.path.join(IMG_DIR, f\"FOLD{fid:02d}_{test_id}_OVERALL_SvWG.png\")\n",
    "\n",
    "    # Single vs Group\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.hist(p_s, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={len(p_s)})\", color=COLOR_SICK)\n",
    "    ax.hist(p_n, bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={len(p_n)})\", color=COLOR_NON)\n",
    "    if np.isfinite(t_single): ax.axvline(t_single, color=COLOR_SINGLE, linestyle=\"-\", linewidth=LW, label=f\"τ_single = {t_single:.3f}\")\n",
    "    if np.isfinite(t_high):   ax.axvline(t_high,   color=COLOR_GROUP,  linestyle=\"--\", linewidth=LW, label=f\"τ_high_{mode} = {t_high:.3f}\")\n",
    "    if np.isfinite(t_low):    ax.axvline(t_low,    color=COLOR_GROUP,  linestyle=\"--\", linewidth=LW, label=f\"τ_low_{mode}  = {t_low:.3f}\")\n",
    "    _style_axes(ax, title=f\"[Fold {fid}] OVERALL — Single vs Group [{mode}]  (test={test_id})\")\n",
    "    ax.legend(fontsize=FS_LEGEND)\n",
    "    plt.tight_layout(); plt.savefig(p_sg, dpi=300); plt.close()\n",
    "    print(f\"[Cell5B++] Saved -> {p_sg}\")\n",
    "\n",
    "    # Single vs WG\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.hist(p_s, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={len(p_s)})\", color=COLOR_SICK)\n",
    "    ax.hist(p_n, bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={len(p_n)})\", color=COLOR_NON)\n",
    "    if np.isfinite(t_single): ax.axvline(t_single, color=COLOR_SINGLE, linestyle=\"-\", linewidth=LW, label=f\"τ_single = {t_single:.3f}\")\n",
    "    if np.isfinite(t_high_w): ax.axvline(t_high_w, color=COLOR_WG,     linestyle=\":\", linewidth=LW, label=f\"τ_high_WG = {t_high_w:.3f}\")\n",
    "    if np.isfinite(t_low_w):  ax.axvline(t_low_w,  color=COLOR_WG,     linestyle=\":\", linewidth=LW, label=f\"τ_low_WG  = {t_low_w:.3f}\")\n",
    "    _style_axes(ax, title=f\"[Fold {fid}] OVERALL — Single vs WG [{mode}]  (test={test_id})\")\n",
    "    ax.legend(fontsize=FS_LEGEND)\n",
    "    plt.tight_layout(); plt.savefig(p_wg, dpi=300); plt.close()\n",
    "    print(f\"[Cell5B++] Saved -> {p_wg}\")\n",
    "\n",
    "print(f\"[Cell5B++] All images saved in: {IMG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5A (FINAL, BA専用): inner-LOSO τ最適化（連結val）→ outer予測・評価 =====\n",
    "# 前提: Cell1〜4 実行済み（X_all, y_all, groups, SUBJECT_META, BEST_K, choose_inner_folds_loso 等）\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------- 基本チェック ----------------\n",
    "req = [\"X_all\",\"y_all\",\"groups\",\"SUBJECT_META\",\n",
    "       \"choose_inner_folds_loso\",\"fit_classifier\",\"predict_positive_score\",\"outpath\"]\n",
    "missing = [v for v in req if v not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f(\"[Cell5A] 未定義の変数/関数があります: {missing}\"))\n",
    "\n",
    "if \"MSSQ_group\" not in SUBJECT_META.columns and \"MSSQ_group\" not in SUBJECT_META.index.names:\n",
    "    raise RuntimeError(\"[Cell5A] SUBJECT_META に MSSQ_group 列（または index）が必要である．\")\n",
    "\n",
    "# ---------------- 設定（等間隔グリッド＋近傍再探索） ----------------\n",
    "COARSE_STEPS = 1001      # 0.0〜1.0 を等間隔\n",
    "FINE_STEPS   = 101       # 近傍再探索の細かさ\n",
    "FINE_MARGIN  = 0.01      # 近傍幅（±0.01）\n",
    "VERBOSE      = True\n",
    "\n",
    "# ---------------- 入力整形 ----------------\n",
    "X_base = X_all.astype(np.float32)\n",
    "y_base = y_all.astype(int)\n",
    "g_base = groups.astype(str)\n",
    "\n",
    "# MSSQ group マッピング（High/Lowに正規化）\n",
    "if \"subject_id\" in SUBJECT_META.columns:\n",
    "    mapper = SUBJECT_META.set_index(\"subject_id\")[\"MSSQ_group\"].astype(str).to_dict()\n",
    "else:\n",
    "    mapper = SUBJECT_META[\"MSSQ_group\"].astype(str).to_dict()\n",
    "\n",
    "fair_groups = g_base.map(mapper).astype(str).str.strip().str.lower().map({\"high\":\"High\",\"low\":\"Low\"})\n",
    "if fair_groups.isna().any():\n",
    "    raise RuntimeError(f\"[Cell5A] MSSQ_group 未割当ID: {sorted(set(g_base[fair_groups.isna()]))}\")\n",
    "\n",
    "# 特徴選抜（SHAP順の上位K）\n",
    "rank_df = pd.read_csv(outpath(\"SHAP_FEATURE_RANKING.CSV\"), index_col=0, encoding=\"utf-8-sig\")\n",
    "feature_order = [f for f in rank_df.index if f in X_base.columns]\n",
    "feats_k = feature_order[:best_k]\n",
    "if len(feats_k) < best_k:\n",
    "    print(f\"[Cell5A][WARN] ランキング上位に X に無い特徴が混在 → {len(feats_k)} 列で実行．\")\n",
    "X_k = X_base[feats_k]\n",
    "\n",
    "if VERBOSE:\n",
    "    print(f\"[DBG] 使用特徴数: {len(feats_k)}  (BEST_K={best_k})\")\n",
    "\n",
    "# ---------------- 指標・評価ユーティリティ（BA専用） ----------------\n",
    "def _conf_from_preds(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    TN, FP, FN, TP = skm.confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    return TP, FP, FN, TN\n",
    "\n",
    "def _ba_from_conf(TP, FP, FN, TN) -> float:\n",
    "    TP = float(TP); FP = float(FP); FN = float(FN); TN = float(TN)\n",
    "    # Sensitivity/TPR と Specificity/TNR\n",
    "    tpr = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    tnr = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "    return 0.5 * (tpr + tnr)\n",
    "\n",
    "def _ba_binary(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    TP, FP, FN, TN = _conf_from_preds(y_true, y_pred)\n",
    "    return _ba_from_conf(TP, FP, FN, TN)\n",
    "\n",
    "def _grid(l, r, steps):\n",
    "    l = float(max(0.0, l)); r = float(min(1.0, r))\n",
    "    if l > r: l, r = r, l\n",
    "    return np.linspace(l, r, int(steps), dtype=float)\n",
    "\n",
    "# ---------------- τ最適化（Single / WG-BA / Group-BA） ----------------\n",
    "def _single_tau_opt(scores: np.ndarray, y: np.ndarray):\n",
    "    # coarse\n",
    "    cands = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "    ba_vec = []\n",
    "    for t in cands:\n",
    "        yhat = (scores >= t).astype(int)\n",
    "        ba_vec.append(_ba_binary(y, yhat))\n",
    "    ba_vec = np.asarray(ba_vec)\n",
    "    idx = int(np.nanargmax(ba_vec)); tau0 = float(cands[idx]); best0 = float(ba_vec[idx])\n",
    "\n",
    "    # fine around tau0\n",
    "    left  = max(0.0, tau0 - FINE_MARGIN)\n",
    "    right = min(1.0, tau0 + FINE_MARGIN)\n",
    "    cands2 = _grid(left, right, FINE_STEPS)\n",
    "    ba_vec2 = []\n",
    "    for t in cands2:\n",
    "        yhat = (scores >= t).astype(int)\n",
    "        ba_vec2.append(_ba_binary(y, yhat))\n",
    "    ba_vec2 = np.asarray(ba_vec2)\n",
    "    idx2 = int(np.nanargmax(ba_vec2)); tau = float(cands2[idx2]); best = float(ba_vec2[idx2])\n",
    "\n",
    "    return {\"tau\": tau, \"BA_val\": best, \"tau_coarse\": tau0, \"BA_coarse\": best0}\n",
    "\n",
    "def _wg_ba_opt_joint(scores: np.ndarray, y: np.ndarray, grp: np.ndarray):\n",
    "    \"\"\"\n",
    "    Fair-MinBA（最悪群BAの最大化）を 2Dグリッド（τH×τL）で探索する．\n",
    "    戻り値: {\"tauH\",\"tauL\",\"BA_H_val\",\"BA_L_val\",\"WG_BA_val\",\"BA_pooled_val\"}\n",
    "    \"\"\"\n",
    "    maskH = (grp == \"High\"); maskL = (grp == \"Low\")\n",
    "    if (maskH.sum()==0) or (maskL.sum()==0):\n",
    "        raise RuntimeError(\"[WG-BA] 連結valに High/Low の両群が必要（どちらかが0件）\")\n",
    "\n",
    "    sH, yH = scores[maskH], y[maskH]\n",
    "    sL, yL = scores[maskL], y[maskL]\n",
    "\n",
    "    candH = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "    candL = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "\n",
    "    def _ba_vec(s, yy, cands):\n",
    "        ba = np.empty_like(cands)\n",
    "        for i, t in enumerate(cands):\n",
    "            yhat = (s >= t).astype(int)\n",
    "            ba[i] = _ba_binary(yy, yhat)\n",
    "        return ba\n",
    "\n",
    "    baH = _ba_vec(sH, yH, candH)\n",
    "    baL = _ba_vec(sL, yL, candL)\n",
    "\n",
    "    best = {\"WG\": -np.inf, \"pooled\": -np.inf, \"tH\": 0.5, \"tL\": 0.5, \"BAH\": 0.0, \"BAL\": 0.0}\n",
    "    for i, tH in enumerate(candH):\n",
    "        wg_row = np.minimum(baH[i], baL)\n",
    "        j = int(np.nanargmax(wg_row))\n",
    "        WG = float(wg_row[j])\n",
    "\n",
    "        yhatH = (sH >= tH).astype(int)\n",
    "        yhatL = (sL >= candL[j]).astype(int)\n",
    "        BA_pooled = _ba_binary(\n",
    "            np.concatenate([yH, yL]),\n",
    "            np.concatenate([yhatH, yhatL])\n",
    "        )\n",
    "\n",
    "        cand = {\"WG\": WG, \"pooled\": float(BA_pooled),\n",
    "                \"tH\": float(tH), \"tL\": float(candL[j]),\n",
    "                \"BAH\": float(baH[i]), \"BAL\": float(baL[j])}\n",
    "\n",
    "        # tie-break: pooled BA → |τH-τL| 小 → (τH,τL) 辞書順小\n",
    "        def _is_better(cur, new):\n",
    "            if new[\"WG\"] > cur[\"WG\"]: return True\n",
    "            if new[\"WG\"] < cur[\"WG\"]: return False\n",
    "            if new[\"pooled\"] > cur[\"pooled\"]: return True\n",
    "            if new[\"pooled\"] < cur[\"pooled\"]: return False\n",
    "            if abs(new[\"tH\"]-new[\"tL\"]) < abs(cur[\"tH\"]-cur[\"tL\"]): return True\n",
    "            if abs(new[\"tH\"]-new[\"tL\"]) > abs(cur[\"tH\"]-cur[\"tL\"]): return False\n",
    "            if (new[\"tH\"], new[\"tL\"]) < (cur[\"tH\"], cur[\"tL\"]): return True\n",
    "            return False\n",
    "\n",
    "        if _is_better(best, cand):\n",
    "            best = cand\n",
    "\n",
    "    # fine (box refine)\n",
    "    lH = max(0.0, best[\"tH\"] - FINE_MARGIN); rH = min(1.0, best[\"tH\"] + FINE_MARGIN)\n",
    "    lL = max(0.0, best[\"tL\"] - FINE_MARGIN); rL = min(1.0, best[\"tL\"] + FINE_MARGIN)\n",
    "    candH2 = _grid(lH, rH, FINE_STEPS)\n",
    "    candL2 = _grid(lL, rL, FINE_STEPS)\n",
    "\n",
    "    baH2 = _ba_vec(sH, yH, candH2)\n",
    "    baL2 = _ba_vec(sL, yL, candL2)\n",
    "\n",
    "    best2 = dict(best)\n",
    "    for i, tH in enumerate(candH2):\n",
    "        wg_row = np.minimum(baH2[i], baL2)\n",
    "        j = int(np.nanargmax(wg_row))\n",
    "        WG = float(wg_row[j])\n",
    "\n",
    "        yhatH = (sH >= tH).astype(int)\n",
    "        yhatL = (sL >= candL2[j]).astype(int)\n",
    "        BA_pooled = _ba_binary(\n",
    "            np.concatenate([yH, yL]),\n",
    "            np.concatenate([yhatH, yhatL])\n",
    "        )\n",
    "        cand = {\"WG\": WG, \"pooled\": float(BA_pooled),\n",
    "                \"tH\": float(tH), \"tL\": float(candL2[j]),\n",
    "                \"BAH\": float(baH2[i]), \"BAL\": float(baL2[j])}\n",
    "\n",
    "        if (cand[\"WG\"] > best2[\"WG\"] or\n",
    "            (cand[\"WG\"] == best2[\"WG\"] and (\n",
    "                cand[\"pooled\"] > best2[\"pooled\"] or\n",
    "                (cand[\"pooled\"] == best2[\"pooled\"] and (\n",
    "                    abs(cand[\"tH\"]-cand[\"tL\"]) < abs(best2[\"tH\"]-best2[\"tL\"]) or\n",
    "                    (abs(cand[\"tH\"]-cand[\"tL\"]) == abs(best2[\"tH\"]-best2[\"tL\"]) and\n",
    "                     (cand[\"tH\"], cand[\"tL\"]) < (best2[\"tH\"], best2[\"tL\"]))\n",
    "                ))\n",
    "            ))):\n",
    "            best2 = cand\n",
    "\n",
    "    return {\n",
    "        \"tauH\": best2[\"tH\"], \"tauL\": best2[\"tL\"],\n",
    "        \"BA_H_val\": best2[\"BAH\"], \"BA_L_val\": best2[\"BAL\"],\n",
    "        \"WG_BA_val\": best2[\"WG\"], \"BA_pooled_val\": best2[\"pooled\"],\n",
    "    }\n",
    "\n",
    "def _group_ba_opt(scores: np.ndarray, y: np.ndarray, grp: np.ndarray):\n",
    "    # 2Dグリッド（τH×τL）で pooled BA 最大化（coarse→fine）\n",
    "    maskH = (grp == \"High\"); maskL = (grp == \"Low\")\n",
    "    if (maskH.sum()==0) or (maskL.sum()==0):\n",
    "        raise RuntimeError(\"[Group-BA] 連結valに High/Low の両群が必要（どちらかが0件）\")\n",
    "\n",
    "    sH, yH = scores[maskH], y[maskH]\n",
    "    sL, yL = scores[maskL], y[maskL]\n",
    "\n",
    "    def _pooled_ba_for(tH, tL):\n",
    "        yhatH = (sH >= tH).astype(int)\n",
    "        yhatL = (sL >= tL).astype(int)\n",
    "        y_true = np.concatenate([yH, yL])\n",
    "        y_pred = np.concatenate([yhatH, yhatL])\n",
    "        return _ba_binary(y_true, y_pred)\n",
    "\n",
    "    candH = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "    candL = _grid(0.0, 1.0, COARSE_STEPS)\n",
    "    best = {\"BA_val\": -np.inf, \"tauH\": None, \"tauL\": None}\n",
    "    for tH in candH:\n",
    "        ba_vec = np.empty_like(candL)\n",
    "        for j, tL in enumerate(candL):\n",
    "            ba_vec[j] = _pooled_ba_for(tH, tL)\n",
    "        jmax = int(np.nanargmax(ba_vec))\n",
    "        if float(ba_vec[jmax]) > best[\"BA_val\"]:\n",
    "            best.update({\"BA_val\": float(ba_vec[jmax]), \"tauH\": float(tH), \"tauL\": float(candL[jmax])})\n",
    "\n",
    "    # fine\n",
    "    lH = max(0.0, best[\"tauH\"] - FINE_MARGIN); rH = min(1.0, best[\"tauH\"] + FINE_MARGIN)\n",
    "    lL = max(0.0, best[\"tauL\"] - FINE_MARGIN); rL = min(1.0, best[\"tauL\"] + FINE_MARGIN)\n",
    "    candH2 = _grid(lH, rH, FINE_STEPS); candL2 = _grid(lL, rL, FINE_STEPS)\n",
    "\n",
    "    best2 = dict(best)\n",
    "    for tH in candH2:\n",
    "        ba_vec2 = np.empty_like(candL2)\n",
    "        for j, tL in enumerate(candL2):\n",
    "            ba_vec2[j] = _pooled_ba_for(tH, tL)\n",
    "        jmax = int(np.nanargmax(ba_vec2))\n",
    "        if float(ba_vec2[jmax]) > best2[\"BA_val\"]:\n",
    "            best2.update({\"BA_val\": float(ba_vec2[jmax]), \"tauH\": float(tH), \"tauL\": float(candL2[jmax])})\n",
    "\n",
    "    return best2  # {\"tauH\",\"tauL\",\"BA_val\"}\n",
    "\n",
    "# ---------------- outer LOSO with inner concatenation ----------------\n",
    "logo_outer = LeaveOneGroupOut()\n",
    "rows, pred_rows = [], []\n",
    "\n",
    "for fold_id, (tr_idx, te_idx) in enumerate(logo_outer.split(X_k, y_base.values, g_base.values), start=1):\n",
    "    train_mask = pd.Series(False, index=g_base.index); train_mask.iloc[tr_idx] = True\n",
    "    test_mask  = pd.Series(False, index=g_base.index);  test_mask.iloc[te_idx]  = True\n",
    "    test_sid = g_base.iloc[te_idx].iloc[0]\n",
    "\n",
    "    # ===== inner folds =====\n",
    "    inner_ids   = sorted(g_base[train_mask].unique())\n",
    "    inner_folds = choose_inner_folds_loso(inner_ids)\n",
    "    if VERBOSE:\n",
    "        print(f\"[inner folds] {len(inner_folds)} splits -> val subjects = {', '.join(inner_ids)}\")\n",
    "\n",
    "    # 連結valの器\n",
    "    val_scores_all, val_y_all, val_grp_all = [], [], []\n",
    "\n",
    "    # --- inner train に両群が居るか（群別τの前提） ---\n",
    "    inner_train_groups = fair_groups[train_mask]\n",
    "    if not ((\"High\" in set(inner_train_groups)) and (\"Low\" in set(inner_train_groups))):\n",
    "        raise RuntimeError(f\"[Cell5A] fold{fold_id}: inner-train に両群(High/Low)が必要（群別τの前提）\")\n",
    "\n",
    "    # ===== inner: train→val 予測の連結 =====\n",
    "    for inner_val in inner_folds:\n",
    "        val_mask  = g_base.isin(inner_val) & train_mask\n",
    "        trn_mask  = train_mask & (~val_mask)\n",
    "        if not trn_mask.any() or not val_mask.any():\n",
    "            continue\n",
    "\n",
    "        X_tr, y_tr = X_k[trn_mask], y_base[trn_mask]\n",
    "        X_vl, y_vl = X_k[val_mask], y_base[val_mask]\n",
    "        grp_vl     = fair_groups[val_mask].to_numpy()\n",
    "\n",
    "        # inner 学習\n",
    "        model_inner = fit_classifier(X_tr, y_tr)\n",
    "        sc_vl = predict_positive_score(model_inner, X_vl).astype(float)\n",
    "\n",
    "        # 連結（生の val 予測）\n",
    "        val_scores_all.append(sc_vl)\n",
    "        val_y_all.append(y_vl.to_numpy())\n",
    "        val_grp_all.append(grp_vl)\n",
    "\n",
    "        if VERBOSE:\n",
    "            nH = int((grp_vl==\"High\").sum()); nL = int((grp_vl==\"Low\").sum())\n",
    "            print(f\"[DBG] fold{fold_id}: inner_val size={len(y_vl):3d}  High={nH} Low={nL}\")\n",
    "\n",
    "    # 連結\n",
    "    if len(val_scores_all) == 0:\n",
    "        raise RuntimeError(f\"[Cell5A] fold{fold_id}: inner validation が空である．\")\n",
    "    s_val = np.concatenate(val_scores_all)\n",
    "    y_val = np.concatenate(val_y_all)\n",
    "    g_val = np.concatenate(val_grp_all)\n",
    "\n",
    "    # ===== 連結valで一度だけ τ を最適化（BA） =====\n",
    "    res_single = _single_tau_opt(s_val, y_val)\n",
    "    tau_single = float(res_single[\"tau\"])\n",
    "\n",
    "    res_wg = _wg_ba_opt_joint(s_val, y_val, g_val)\n",
    "    tauH_wg, tauL_wg = float(res_wg[\"tauH\"]), float(res_wg[\"tauL\"])\n",
    "\n",
    "    res_group = _group_ba_opt(s_val, y_val, g_val)\n",
    "    tauH_grp, tauL_grp = float(res_group[\"tauH\"]), float(res_group[\"tauL\"])\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"[DBG] fold{fold_id}: tau_single={tau_single:.6f} | \"\n",
    "              f\"Group-BA(tH,tL)=({tauH_grp:.6f},{tauL_grp:.6f}) | \"\n",
    "              f\"WG-BA(tH,tL)=({tauH_wg:.6f},{tauL_wg:.6f})\")\n",
    "\n",
    "    # ===== outer test =====\n",
    "    X_tr_o, y_tr_o = X_k[train_mask], y_base[train_mask]\n",
    "    X_te_o, y_te_o = X_k[test_mask],  y_base[test_mask]\n",
    "    grp_te         = fair_groups[test_mask].to_numpy()\n",
    "\n",
    "    model_outer = fit_classifier(X_tr_o, y_tr_o)\n",
    "    sc_te = predict_positive_score(model_outer, X_te_o).astype(float)\n",
    "\n",
    "    yhat_single = (sc_te >= tau_single).astype(int)\n",
    "    yhat_groupBA = (sc_te >= np.where(grp_te==\"High\", tauH_grp, tauL_grp)).astype(int)\n",
    "    yhat_wgBA    = (sc_te >= np.where(grp_te==\"High\", tauH_wg,  tauL_wg )).astype(int)\n",
    "\n",
    "    BA_single = _ba_binary(y_te_o.to_numpy(), yhat_single)\n",
    "    BA_group  = _ba_binary(y_te_o.to_numpy(), yhat_groupBA)\n",
    "    BA_wg     = _ba_binary(y_te_o.to_numpy(), yhat_wgBA)\n",
    "\n",
    "    if VERBOSE:\n",
    "        same_grp = bool(np.array_equal(yhat_single, yhat_groupBA))\n",
    "        same_wg  = bool(np.array_equal(yhat_single, yhat_wgBA))\n",
    "        nH_te = int((grp_te==\"High\").sum()); nL_te = int((grp_te==\"Low\").sum())\n",
    "        print(f\"[DBG] fold{fold_id}: TEST High={nH_te} Low={nL_te} | \"\n",
    "              f\"Single==Group-BA: {same_grp}  Single==WG-BA: {same_wg} | \"\n",
    "              f\"BA(single, group, wg)=({BA_single:.3f}, {BA_group:.3f}, {BA_wg:.3f})\")\n",
    "\n",
    "    rows.append({\n",
    "        \"fold_id\": int(fold_id),\n",
    "        \"test_id\": str(test_sid),\n",
    "        \"best_k\": int(best_k),\n",
    "        \"tau_single\": float(tau_single),\n",
    "        \"tau_high_GroupBA\": float(tauH_grp), \"tau_low_GroupBA\": float(tauL_grp),\n",
    "        \"tau_high_WGBA\": float(tauH_wg),     \"tau_low_WGBA\": float(tauL_wg),\n",
    "        \"BA_single\": float(BA_single),\n",
    "        \"BA_group\":  float(BA_group),\n",
    "        \"BA_group_WG\": float(BA_wg),\n",
    "        \"n_test\": int(len(y_te_o)),\n",
    "    })\n",
    "\n",
    "    # 予測詳細（BA専用命名）\n",
    "    for yy, ss, gg, ys, yg, yw in zip(y_te_o, sc_te, grp_te, yhat_single, yhat_groupBA, yhat_wgBA):\n",
    "        pred_rows.append({\n",
    "            \"fold_id\": int(fold_id),\n",
    "            \"test_id\": str(test_sid),\n",
    "            \"y_true\": int(yy),\n",
    "            \"proba\": float(ss),\n",
    "            \"group\": str(gg),\n",
    "            \"y_pred_single\": int(ys),\n",
    "            \"y_pred_group_BA\": int(yg),\n",
    "            \"y_pred_group_WG\": int(yw),\n",
    "        })\n",
    "    \n",
    "    print(f\"[DBG] fold{fold_id}: WG-joint val -> \"\n",
    "          f\"BA_H={res_wg['BA_H_val']:.3f}, BA_L={res_wg['BA_L_val']:.3f}, \"\n",
    "          f\"WG(BA)={res_wg['WG_BA_val']:.3f}, pooled(BA)={res_wg['BA_pooled_val']:.3f}, \"\n",
    "          f\"(tH,tL)=({tauH_wg:.4f},{tauL_wg:.4f})\")\n",
    "\n",
    "# ---------------- 出力 ----------------\n",
    "df_fold = pd.DataFrame(rows)\n",
    "df_pred = pd.DataFrame(pred_rows)\n",
    "df_fold.to_csv(outpath(\"GROUP_AWARE_THRESH_BY_FOLD.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "df_pred.to_csv(outpath(\"GROUP_AWARE_PREDICTIONS.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 参考: プールAUC（確率は共通なので1つ）\n",
    "auc_pool = float(roc_auc_score(df_pred[\"y_true\"].to_numpy(), df_pred[\"proba\"].to_numpy()))\n",
    "\n",
    "def _pooled_ba(col):\n",
    "    y_true = df_pred[\"y_true\"].to_numpy()\n",
    "    yhat   = df_pred[col].to_numpy().astype(int)\n",
    "    return _ba_binary(y_true, yhat)\n",
    "\n",
    "summary = {\n",
    "    \"best_k\": int(best_k),\n",
    "    \"AUC_pooled\": auc_pool,  # 不要ならこのキーごと削除可\n",
    "    \"BA_pooled_single\": _pooled_ba(\"y_pred_single\"),\n",
    "    \"BA_pooled_group\":  _pooled_ba(\"y_pred_group_BA\"),\n",
    "    \"BA_pooled_group_WG\": _pooled_ba(\"y_pred_group_WG\"),\n",
    "    \"metric\": \"BA\",\n",
    "    \"n_samples\": int(len(df_pred)),\n",
    "    \"n_pos\": int((df_pred[\"y_true\"]==1).sum()),\n",
    "    \"n_neg\": int((df_pred[\"y_true\"]==0).sum()),\n",
    "}\n",
    "pd.DataFrame([summary]).to_csv(outpath(\"GROUP_AWARE_SUMMARY.CSV\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"[Cell5A] Done: outer folds={len(df_fold)}, pooled AUC={auc_pool:.3f}\")\n",
    "print(f\"[Cell5A] Summary: {summary}\")\n",
    "\n",
    "# ---------------- 混同行列プロット（BA専用タイトル） ----------------\n",
    "def _draw_cm(cm, title, path):\n",
    "    fig, ax = plt.subplots(figsize=(7,6))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\", vmin=0, vmax=max(cm.max(),1))\n",
    "    labels = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            val = int(cm[i,j])\n",
    "            color = \"white\" if val > 0.6*im.get_clim()[1] else \"black\"\n",
    "            ax.text(j, i, f\"{labels[i,j]}\\n{val}\", ha=\"center\", va=\"center\",\n",
    "                    fontsize=18, fontweight=\"bold\", color=color)\n",
    "    ax.set_xticks([0,1]); ax.set_xticklabels([\"Pred:0\",\"Pred:1\"])\n",
    "    ax.set_yticks([0,1]); ax.set_yticklabels([\"True:0\",\"True:1\"], rotation=90, va=\"center\")\n",
    "    ax.set_title(title); ax.grid(False)\n",
    "    plt.tight_layout(); plt.savefig(path, dpi=300); plt.close()\n",
    "\n",
    "y_pool = df_pred[\"y_true\"].to_numpy()\n",
    "cm_single = skm.confusion_matrix(y_pool, df_pred[\"y_pred_single\"],   labels=[0,1])\n",
    "cm_group  = skm.confusion_matrix(y_pool, df_pred[\"y_pred_group_BA\"], labels=[0,1])\n",
    "cm_wg     = skm.confusion_matrix(y_pool, df_pred[\"y_pred_group_WG\"], labels=[0,1])\n",
    "\n",
    "_draw_cm(cm_single, f\"Cell5A Single τ (BA={summary['BA_pooled_single']:.3f})\",\n",
    "         outpath(\"CONFMAT_CELL5A_SINGLE(BA).png\"))\n",
    "_draw_cm(cm_group,  f\"Cell5A Group-BA τ (BA={summary['BA_pooled_group']:.3f})\",\n",
    "         outpath(\"CONFMAT_CELL5A_GROUP(BA).png\"))\n",
    "_draw_cm(cm_wg,     f\"Cell5A WG-BA τ (BA={summary['BA_pooled_group_WG']:.3f})\",\n",
    "         outpath(\"CONFMAT_CELL5A_WG(BA).png\"))\n",
    "print(\"[Cell5A] Confusion matrices saved -> CONFMAT_CELL5A_*.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6eb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5B++: 確率スコア分布（OVERALL/群別/各Fold）＋ τ の中央値/IQR 帯・±表記 =====\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- 設定 ----------\n",
    "BINS = 40\n",
    "LW = 1.5\n",
    "FS_TITLE, FS_LABEL, FS_LEGEND, FS_TICK = 30, 24, 20, 20\n",
    "\n",
    "# 色指定（ユーザ指定）\n",
    "COLOR_SICK = \"red\"   # True:Sick\n",
    "COLOR_NON  = \"blue\"  # True:Non-Sick\n",
    "\n",
    "# 線色（しきい値）\n",
    "COLOR_SINGLE = \"black\"\n",
    "COLOR_GROUP  = \"green\"\n",
    "COLOR_WG     = \"purple\"\n",
    "\n",
    "# 出力フォルダ（新規作成）\n",
    "RUN_ROOT = os.path.dirname(outpath(\"__dummy__\"))\n",
    "IMG_DIR  = os.path.join(RUN_ROOT, \"PROBA_DIST_BA\")\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "# ファイルパス\n",
    "SAVE_OVERALL_SvG   = os.path.join(IMG_DIR, \"OVERALL_SvGroup.png\")\n",
    "SAVE_OVERALL_SvWG  = os.path.join(IMG_DIR, \"OVERALL_SvWG.png\")\n",
    "SAVE_BYGROUP_SvG   = os.path.join(IMG_DIR, \"BYGROUP_SvGroup.png\")\n",
    "SAVE_BYGROUP_SvWG  = os.path.join(IMG_DIR, \"BYGROUP_SvWG.png\")\n",
    "\n",
    "# ---------- 入力 ----------\n",
    "pred_path = outpath(\"GROUP_AWARE_PREDICTIONS.CSV\")\n",
    "fold_path = outpath(\"GROUP_AWARE_THRESH_BY_FOLD.CSV\")\n",
    "if not (os.path.exists(pred_path) and os.path.exists(fold_path)):\n",
    "    raise FileNotFoundError(\"[Cell5B++] 必要CSVが見つからない（Cell 5A を先に実行）\")\n",
    "\n",
    "df_pred = pd.read_csv(pred_path, encoding=\"utf-8-sig\")\n",
    "df_fold = pd.read_csv(fold_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "# ---------- モード自動判定（F1 or BA） ----------\n",
    "cols_f1 = {\"high\":\"tau_high_GroupF1\", \"low\":\"tau_low_GroupF1\", \"wgh\":\"tau_high_WGF1\", \"wgl\":\"tau_low_WGF1\"}\n",
    "cols_ba = {\"high\":\"tau_high_GroupBA\", \"low\":\"tau_low_GroupBA\", \"wgh\":\"tau_high_WGBA\", \"wgl\":\"tau_low_WGBA\"}\n",
    "\n",
    "if all(c in df_fold.columns for c in [cols_f1[\"high\"], cols_f1[\"low\"]]):\n",
    "    mode = \"F1\"\n",
    "    c_high, c_low, c_wgh, c_wgl = cols_f1[\"high\"], cols_f1[\"low\"], cols_f1[\"wgh\"], cols_f1[\"wgl\"]\n",
    "    pred_group_col = \"y_pred_group_F1\"\n",
    "elif all(c in df_fold.columns for c in [cols_ba[\"high\"], cols_ba[\"low\"]]):\n",
    "    mode = \"BA\"\n",
    "    c_high, c_low, c_wgh, c_wgl = cols_ba[\"high\"], cols_ba[\"low\"], cols_ba[\"wgh\"], cols_ba[\"wgl\"]\n",
    "    pred_group_col = \"y_pred_group_BA\"\n",
    "else:\n",
    "    raise RuntimeError(\"[Cell5B++] しきい値列が見つからない（F1/BAどちらかのCell 5Aの出力が必要）\")\n",
    "\n",
    "# ---------- 集約: 中央値/IQR（Q1〜Q3） ----------\n",
    "def _qstats(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    s = s[np.isfinite(s)]\n",
    "    if s.size == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan  # med, q1, q3, half_iqr\n",
    "    med = float(np.nanmedian(s))\n",
    "    q1, q3 = np.nanpercentile(s, [25, 75])\n",
    "    half = float((q3 - q1)/2.0)\n",
    "    return float(med), float(q1), float(q3), half\n",
    "\n",
    "tau_single_med, tau_single_q1, tau_single_q3, tau_single_half = _qstats(df_fold[\"tau_single\"])\n",
    "tau_high_med,   tau_high_q1,   tau_high_q3,   tau_high_half   = _qstats(df_fold[c_high])\n",
    "tau_low_med,    tau_low_q1,    tau_low_q3,    tau_low_half    = _qstats(df_fold[c_low])\n",
    "tau_high_wg,    tau_high_wg_q1, tau_high_wg_q3, tau_high_wg_half = _qstats(df_fold[c_wgh]) if c_wgh in df_fold.columns else (np.nan, np.nan, np.nan, np.nan)\n",
    "tau_low_wg,     tau_low_wg_q1,  tau_low_wg_q3,  tau_low_wg_half  = _qstats(df_fold[c_wgl]) if c_wgl in df_fold.columns else (np.nan, np.nan, np.nan, np.nan)\n",
    "\n",
    "# ---------- データ分解 ----------\n",
    "proba = pd.to_numeric(df_pred[\"proba\"], errors=\"coerce\").values\n",
    "ytrue = pd.to_numeric(df_pred[\"y_true\"], errors=\"coerce\").values.astype(int)\n",
    "grp   = df_pred[\"group\"].astype(str).str.strip()\n",
    "\n",
    "p_sick = proba[ytrue == 1]   # True:Sick\n",
    "p_non  = proba[ytrue == 0]   # True:Non-Sick\n",
    "n_sick, n_non = len(p_sick), len(p_non)\n",
    "\n",
    "maskH = (grp == \"High\"); maskL = (grp == \"Low\")\n",
    "\n",
    "# ---------- ユーティリティ ----------\n",
    "def _style_axes(ax, title=None):\n",
    "    if title: ax.set_title(title, fontsize=FS_TITLE)\n",
    "    ax.set_xlabel(\"Predicted probability\", fontsize=FS_LABEL)\n",
    "    ax.set_ylabel(\"Density\", fontsize=FS_LABEL)\n",
    "    ax.tick_params(axis=\"both\", labelsize=FS_TICK)\n",
    "    ax.set_xlim(0, 1)\n",
    "\n",
    "def _hist_overall(ax):\n",
    "    ax.hist(p_sick, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={n_sick})\", color=COLOR_SICK)\n",
    "    ax.hist(p_non,  bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={n_non})\", color=COLOR_NON)\n",
    "\n",
    "def _hist_bygroup(axes):\n",
    "    # High\n",
    "    p_sick_H = proba[(ytrue==1) & maskH]; p_non_H = proba[(ytrue==0) & maskH]\n",
    "    axes[0].hist(p_sick_H, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={len(p_sick_H)})\", color=COLOR_SICK)\n",
    "    axes[0].hist(p_non_H,  bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={len(p_non_H)})\", color=COLOR_NON)\n",
    "    _style_axes(axes[0], \"High group\")\n",
    "    # Low\n",
    "    p_sick_L = proba[(ytrue==1) & maskL]; p_non_L = proba[(ytrue==0) & maskL]\n",
    "    axes[1].hist(p_sick_L, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={len(p_sick_L)})\", color=COLOR_SICK)\n",
    "    axes[1].hist(p_non_L,  bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={len(p_non_L)})\", color=COLOR_NON)\n",
    "    _style_axes(axes[1], \"Low group\")\n",
    "\n",
    "def _vline_with_iqr(ax, x_med, q1, q3, color, ls, label_core):\n",
    "    if np.isfinite(x_med):\n",
    "        ax.axvline(x_med, color=color, linestyle=ls, linewidth=LW,\n",
    "                   label=f\"{label_core} = {x_med:.3f} ± {(q3-q1)/2:.3f}\" if (np.isfinite(q1) and np.isfinite(q3)) else f\"{label_core} = {x_med:.3f}\")\n",
    "    if np.isfinite(q1) and np.isfinite(q3):\n",
    "        ax.axvspan(q1, q3, color=color, alpha=0.12)\n",
    "\n",
    "# ---------- 1) OVERALL: Single vs Group（中央値・IQR帯・±表記） ----------\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "_hist_overall(ax)\n",
    "_vline_with_iqr(ax, tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(ax, tau_high_med,   tau_high_q1,   tau_high_q3,   COLOR_GROUP,  \"--\", f\"τ_high_{mode}\")\n",
    "_vline_with_iqr(ax, tau_low_med,    tau_low_q1,    tau_low_q3,    COLOR_GROUP,  \"--\", f\"τ_low_{mode}\")\n",
    "_style_axes(ax, title=f\"Probability distribution (OVERALL) — Single vs Group [{mode}]\")\n",
    "ax.legend(fontsize=FS_LEGEND)\n",
    "plt.tight_layout(); plt.savefig(SAVE_OVERALL_SvG, dpi=300); plt.close()\n",
    "print(f\"[Cell5B++] Saved -> {SAVE_OVERALL_SvG}\")\n",
    "\n",
    "# ---------- 2) OVERALL: Single vs WG（中央値・IQR帯・±表記） ----------\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "_hist_overall(ax)\n",
    "_vline_with_iqr(ax, tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(ax, tau_high_wg,    tau_high_wg_q1, tau_high_wg_q3, COLOR_WG, \":\", \"τ_high_WG\")\n",
    "_vline_with_iqr(ax, tau_low_wg,     tau_low_wg_q1,  tau_low_wg_q3,  COLOR_WG, \":\", \"τ_low_WG\")\n",
    "_style_axes(ax, title=f\"Probability distribution (OVERALL) — Single vs WG [{mode}]\")\n",
    "ax.legend(fontsize=FS_LEGEND)\n",
    "plt.tight_layout(); plt.savefig(SAVE_OVERALL_SvWG, dpi=300); plt.close()\n",
    "print(f\"[Cell5B++] Saved -> {SAVE_OVERALL_SvWG}\")\n",
    "\n",
    "# ---------- 3) BY_GROUP: Single vs Group（各群パネルに該当の IQR帯） ----------\n",
    "fig, axes = plt.subplots(2, 1, figsize=(9,10), sharex=True)\n",
    "_hist_bygroup(axes)\n",
    "# Single は両段に表示\n",
    "_vline_with_iqr(axes[0], tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(axes[1], tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "# High 段に High の Group τ、Low 段に Low の Group τ\n",
    "_vline_with_iqr(axes[0], tau_high_med, tau_high_q1, tau_high_q3, COLOR_GROUP, \"--\", f\"τ_high_{mode}\")\n",
    "_vline_with_iqr(axes[1], tau_low_med,  tau_low_q1,  tau_low_q3,  COLOR_GROUP, \"--\", f\"τ_low_{mode}\")\n",
    "axes[0].legend(fontsize=FS_LEGEND); axes[1].legend(fontsize=FS_LEGEND)\n",
    "plt.tight_layout(); plt.savefig(SAVE_BYGROUP_SvG, dpi=300); plt.close()\n",
    "print(f\"[Cell5B++] Saved -> {SAVE_BYGROUP_SvG}\")\n",
    "\n",
    "# ---------- 4) BY_GROUP: Single vs WG（各群パネルに該当の IQR帯） ----------\n",
    "fig, axes = plt.subplots(2, 1, figsize=(9,10), sharex=True)\n",
    "_hist_bygroup(axes)\n",
    "_vline_with_iqr(axes[0], tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(axes[1], tau_single_med, tau_single_q1, tau_single_q3, COLOR_SINGLE, \"-\", \"τ_single\")\n",
    "_vline_with_iqr(axes[0], tau_high_wg, tau_high_wg_q1, tau_high_wg_q3, COLOR_WG, \":\", \"τ_high_WG\")\n",
    "_vline_with_iqr(axes[1], tau_low_wg,  tau_low_wg_q1,  tau_low_wg_q3,  COLOR_WG, \":\", \"τ_low_WG\")\n",
    "axes[0].legend(fontsize=FS_LEGEND); axes[1].legend(fontsize=FS_LEGEND)\n",
    "plt.tight_layout(); plt.savefig(SAVE_BYGROUP_SvWG, dpi=300); plt.close()\n",
    "print(f\"[Cell5B++] Saved -> {SAVE_BYGROUP_SvWG}\")\n",
    "\n",
    "# ---------- 5) Fold単位：OVERALL の確率分布と各Foldの τ（Single vs Group / Single vs WG） ----------\n",
    "#   - 各Foldのテストサンプルのみでヒストを作図\n",
    "#   - しきい値は「そのFold行」の値を直接表示（±は不要／IQR帯は使わない）\n",
    "for _, row in df_fold.iterrows():\n",
    "    fid = int(row[\"fold_id\"]) if \"fold_id\" in row else None\n",
    "    test_id = str(row.get(\"test_id\", f\"fold{fid}\"))\n",
    "    sub = df_pred[df_pred[\"fold_id\"] == fid] if \"fold_id\" in df_pred.columns and fid is not None else df_pred.copy()\n",
    "\n",
    "    p = pd.to_numeric(sub[\"proba\"], errors=\"coerce\").values\n",
    "    yt = pd.to_numeric(sub[\"y_true\"], errors=\"coerce\").values.astype(int)\n",
    "    p_s, p_n = p[yt==1], p[yt==0]\n",
    "\n",
    "    # 値（このFoldの τ）\n",
    "    t_single = float(row[\"tau_single\"])\n",
    "    t_high   = float(row[c_high]) if c_high in row else np.nan\n",
    "    t_low    = float(row[c_low])  if c_low  in row else np.nan\n",
    "    t_high_w = float(row[c_wgh])  if c_wgh  in row else np.nan\n",
    "    t_low_w  = float(row[c_wgl])  if c_wgl  in row else np.nan\n",
    "\n",
    "    # 出力パス\n",
    "    p_sg  = os.path.join(IMG_DIR, f\"FOLD{fid:02d}_{test_id}_OVERALL_SvGroup.png\")\n",
    "    p_wg  = os.path.join(IMG_DIR, f\"FOLD{fid:02d}_{test_id}_OVERALL_SvWG.png\")\n",
    "\n",
    "    # Single vs Group\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.hist(p_s, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={len(p_s)})\", color=COLOR_SICK)\n",
    "    ax.hist(p_n, bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={len(p_n)})\", color=COLOR_NON)\n",
    "    if np.isfinite(t_single): ax.axvline(t_single, color=COLOR_SINGLE, linestyle=\"-\", linewidth=LW, label=f\"τ_single = {t_single:.3f}\")\n",
    "    if np.isfinite(t_high):   ax.axvline(t_high,   color=COLOR_GROUP,  linestyle=\"--\", linewidth=LW, label=f\"τ_high_{mode} = {t_high:.3f}\")\n",
    "    if np.isfinite(t_low):    ax.axvline(t_low,    color=COLOR_GROUP,  linestyle=\"--\", linewidth=LW, label=f\"τ_low_{mode}  = {t_low:.3f}\")\n",
    "    _style_axes(ax, title=f\"[Fold {fid}] OVERALL — Single vs Group [{mode}]  (test={test_id})\")\n",
    "    ax.legend(fontsize=FS_LEGEND)\n",
    "    plt.tight_layout(); plt.savefig(p_sg, dpi=300); plt.close()\n",
    "    print(f\"[Cell5B++] Saved -> {p_sg}\")\n",
    "\n",
    "    # Single vs WG\n",
    "    fig, ax = plt.subplots(figsize=(9,6))\n",
    "    ax.hist(p_s, bins=BINS, density=True, alpha=0.5, label=f\"True:Sick (n={len(p_s)})\", color=COLOR_SICK)\n",
    "    ax.hist(p_n, bins=BINS, density=True, alpha=0.5, label=f\"True:Non-Sick (n={len(p_n)})\", color=COLOR_NON)\n",
    "    if np.isfinite(t_single): ax.axvline(t_single, color=COLOR_SINGLE, linestyle=\"-\", linewidth=LW, label=f\"τ_single = {t_single:.3f}\")\n",
    "    if np.isfinite(t_high_w): ax.axvline(t_high_w, color=COLOR_WG,     linestyle=\":\", linewidth=LW, label=f\"τ_high_WG = {t_high_w:.3f}\")\n",
    "    if np.isfinite(t_low_w):  ax.axvline(t_low_w,  color=COLOR_WG,     linestyle=\":\", linewidth=LW, label=f\"τ_low_WG  = {t_low_w:.3f}\")\n",
    "    _style_axes(ax, title=f\"[Fold {fid}] OVERALL — Single vs WG [{mode}]  (test={test_id})\")\n",
    "    ax.legend(fontsize=FS_LEGEND)\n",
    "    plt.tight_layout(); plt.savefig(p_wg, dpi=300); plt.close()\n",
    "    print(f\"[Cell5B++] Saved -> {p_wg}\")\n",
    "\n",
    "print(f\"[Cell5B++] All images saved in: {IMG_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
