{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "892ae084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]  Load -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\summary_scores.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell 1: setup & utilities (load from summary_scores.csv) ===\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "BASE_DIR: str = r\"C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\"\n",
    "INPUT_SUMMARY: str = os.path.join(BASE_DIR, \"summary_scores.csv\")  # ★ ここを固定読み込み\n",
    "OUT_PLOTS_CORR: str = os.path.join(BASE_DIR, \"ANALYSIS\", \"plots\", \"correlation\")\n",
    "OUT_PLOTS_DIST: str = os.path.join(BASE_DIR, \"ANALYSIS\", \"plots\", \"distribution\")\n",
    "OUT_TABLES: str = os.path.join(BASE_DIR, \"ANALYSIS\", \"tables\")\n",
    "CORR_TABLE_PATH: str = os.path.join(OUT_TABLES, \"correlation_summary.csv\")\n",
    "REG_TABLE_PATH: str = os.path.join(OUT_TABLES, \"regression_summary.csv\")\n",
    "\n",
    "subjects = [\n",
    "    (\"0521\", \"因幡先生\"),\n",
    "    (\"06021\", \"今村さん\"),\n",
    "    (\"06022\", \"梅野さん\"),\n",
    "    (\"06271\", \"\"),\n",
    "    (\"06272\", \"\"),\n",
    "    (\"06273\", \"\"),\n",
    "    (\"06274\", \"\"),\n",
    "    (\"06275\", \"\")\n",
    "]\n",
    "\n",
    "\n",
    "# 図の体裁（あなたの規約）\n",
    "TITLE_FSIZE = 30\n",
    "LABEL_FSIZE = 24\n",
    "LEGEND_FSIZE = 20\n",
    "TICK_FSIZE = 20\n",
    "LINEWIDTH = 1.5\n",
    "\n",
    "# テーブル書き込み挙動\n",
    "OVERWRITE_TABLES: bool = True  # セル2実行時に初期化、以後は追記\n",
    "\n",
    "# 列名エイリアス辞書（あなたの集計スクリプト列に対応）\n",
    "ALIASES: Dict[str, List[str]] = {\n",
    "    \"subject_id\":  [\"id\", \"subject_id\", \"subject\"],\n",
    "    \"MSSQ\":        [\"mssq\", \"mssq_total\", \"mssq score\", \"mssq_total_score\"],\n",
    "    \"VIMSSQ\":      [\"vimssq\", \"vims_susceptibility\", \"vims susceptibility\", \"mssq_v\"],\n",
    "    \"SSQ_TOTAL\":   [\"ssq_total\", \"ssq total\", \"ssq sum\", \"ssq_sum\", \"ssqtotal\", \"ssq_total_score\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"ssq_totalvalue\", \"SSQ_Total\"],\n",
    "    \"SSQ_NAUSEA\":  [\"ssq_nausea\", \"nausea\", \"ssq nausea\", \"SSQ_Nausea\"],\n",
    "    \"FMS_MAX\":     [\"max_fms\", \"fmsmax\", \"MAX_FMS\"],\n",
    "}\n",
    "\n",
    "N_MIN: int = 3  # 相関・回帰の最小サンプル数\n",
    "\n",
    "# ===================== UTILS =====================\n",
    "def _normalize(s: str) -> str:\n",
    "    import re\n",
    "    return re.sub(r\"[^0-9a-z_]\", \"\", s.strip().lower().replace(\" \", \"_\"))\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame, aliases: Dict[str, List[str]]) -> pd.DataFrame:\n",
    "    inv_map: Dict[str, str] = {}\n",
    "    norm_cols = {_normalize(c): c for c in df.columns}\n",
    "    for std, cands in aliases.items():\n",
    "        for cand in [std] + cands:\n",
    "            key = _normalize(cand)\n",
    "            if key in norm_cols:\n",
    "                inv_map[norm_cols[key]] = std\n",
    "                break\n",
    "    return df.rename(columns=inv_map)\n",
    "\n",
    "def ensure_dirs(*paths: str) -> None:\n",
    "    for p in paths:\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def fisher_z_ci(r: float, n: int, alpha: float = 0.05) -> Tuple[float, float]:\n",
    "    if n <= 3 or not np.isfinite(r) or abs(r) >= 0.999999:\n",
    "        return (np.nan, np.nan)\n",
    "    z = np.arctanh(np.clip(r, -0.999999, 0.999999))\n",
    "    se = 1.0 / math.sqrt(n - 3)\n",
    "    zcrit = stats.norm.ppf(1 - alpha / 2)\n",
    "    return (np.tanh(z - zcrit * se), np.tanh(z + zcrit * se))\n",
    "\n",
    "def compute_correlation(x: np.ndarray, y: np.ndarray) -> Tuple[int, float, float, float, float]:\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x_, y_ = x[mask], y[mask]\n",
    "    n = x_.shape[0]\n",
    "    if n < N_MIN:\n",
    "        return (n, np.nan, np.nan, np.nan, np.nan)\n",
    "    r, p = stats.pearsonr(x_, y_)\n",
    "    r_lo, r_hi = fisher_z_ci(r, n)\n",
    "    return (n, r, p, r_lo, r_hi)\n",
    "\n",
    "def compute_regression(x: np.ndarray, y: np.ndarray) -> Tuple[int, float, float, float, float, float]:\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x_, y_ = x[mask], y[mask]\n",
    "    n = x_.shape[0]\n",
    "    if n < N_MIN or np.std(x_) == 0 or np.std(y_) == 0:\n",
    "        return (n, np.nan, np.nan, np.nan, np.nan, np.nan)\n",
    "    res = stats.linregress(x_, y_)\n",
    "    return (n, res.slope, res.intercept, res.rvalue, res.rvalue**2, res.pvalue)\n",
    "\n",
    "def plot_scatter_with_fit(df: pd.DataFrame, x_col: str, y_col: str, out_png: str,\n",
    "                          title: Optional[str] = None,\n",
    "                          annotate_stats: Optional[Tuple[int, float, float]] = None) -> bool:\n",
    "    try:\n",
    "        x = pd.to_numeric(df[x_col], errors=\"coerce\").to_numpy()\n",
    "        y = pd.to_numeric(df[y_col], errors=\"coerce\").to_numpy()\n",
    "        mask = np.isfinite(x) & np.isfinite(y)\n",
    "        x_, y_ = x[mask], y[mask]\n",
    "        if x_.size < N_MIN or np.std(x_) == 0 or np.std(y_) == 0:\n",
    "            print(f\"[SKIP] {x_col} vs {y_col}: insufficient or constant data\")\n",
    "            return False\n",
    "        reg = stats.linregress(x_, y_)\n",
    "        xfit = np.linspace(x_.min(), x_.max(), 100)\n",
    "        yfit = reg.slope * xfit + reg.intercept\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7, 5))\n",
    "        ax.scatter(x_, y_, s=60, alpha=0.7)\n",
    "        ax.plot(xfit, yfit, linewidth=LINEWIDTH)\n",
    "        ax.set_title(title or f\"{x_col} vs {y_col}\", fontsize=TITLE_FSIZE)\n",
    "        ax.set_xlabel(x_col, fontsize=LABEL_FSIZE)\n",
    "        ax.set_ylabel(y_col, fontsize=LABEL_FSIZE)\n",
    "        ax.tick_params(axis=\"both\", labelsize=TICK_FSIZE)\n",
    "        if annotate_stats is not None:\n",
    "            n, r, p = annotate_stats\n",
    "            ax.text(0.98, 0.02, f\"N={n}, r={r:.3f}, p={p:.3g}\",\n",
    "                    transform=ax.transAxes, ha=\"right\", va=\"bottom\", fontsize=LEGEND_FSIZE)\n",
    "        ensure_dirs(os.path.dirname(out_png))\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(f\"[OK]  {x_col} vs {y_col} -> {out_png}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] {x_col} vs {y_col}: {e}\")\n",
    "        return False\n",
    "\n",
    "def init_tables(corr_csv: str, reg_csv: str, overwrite: bool) -> None:\n",
    "    ensure_dirs(OUT_TABLES)\n",
    "    if overwrite:\n",
    "        for p in (corr_csv, reg_csv):\n",
    "            if os.path.exists(p):\n",
    "                try: os.remove(p)\n",
    "                except Exception: pass\n",
    "\n",
    "def append_corr_row(path: str, row: Dict) -> None:\n",
    "    df = pd.DataFrame([row])\n",
    "    df.to_csv(path, mode=\"a\", index=False, header=not os.path.exists(path))\n",
    "\n",
    "def append_reg_row(path: str, row: Dict) -> None:\n",
    "    df = pd.DataFrame([row])\n",
    "    df.to_csv(path, mode=\"a\", index=False, header=not os.path.exists(path))\n",
    "\n",
    "# ===================== LOAD DATA =====================\n",
    "ensure_dirs(OUT_PLOTS_CORR, OUT_PLOTS_DIST, OUT_TABLES)\n",
    "\n",
    "df_in: Optional[pd.DataFrame] = None\n",
    "if os.path.exists(INPUT_SUMMARY):\n",
    "    try:\n",
    "        df_in = pd.read_csv(INPUT_SUMMARY)\n",
    "        print(f\"[OK]  Load -> {INPUT_SUMMARY}\")\n",
    "        df_in = standardize_columns(df_in, ALIASES)\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] Load: {INPUT_SUMMARY} ({e})\")\n",
    "else:\n",
    "    print(f\"[SKIP] Load: not found {INPUT_SUMMARY}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c1391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]  MSSQ vs SSQ_TOTAL -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\MSSQ_vs_SSQ_Total.png\n",
      "[OK]  MSSQ vs SSQ_NAUSEA -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\MSSQ_vs_SSQ_Nausea.png\n",
      "[OK]  MSSQ vs FMS_MAX -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\MSSQ_vs_MAX_FMS.png\n",
      "[OK]  VIMSSQ vs SSQ_TOTAL -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\VIMSSQ_vs_SSQ_Total.png\n",
      "[OK]  VIMSSQ vs SSQ_NAUSEA -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\VIMSSQ_vs_SSQ_Nausea.png\n",
      "[OK]  VIMSSQ vs FMS_MAX -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\VIMSSQ_vs_MAX_FMS.png\n",
      "[OK]  MSSQ vs VIMSSQ -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\MSSQ_vs_VIMSSQ.png\n",
      "[OK]  Table(corr) -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\tables\\correlation_summary.csv\n",
      "[OK]  Table(reg)  -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\tables\\regression_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2 : styled scatter with regression & 95% CI, labels, cutoffs ===\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "if df_in is None:\n",
    "    raise SystemExit(\"[SKIP] No input DataFrame loaded in Cell 1.\")\n",
    "\n",
    "# ---------- helpers: labels / colors / display names ----------\n",
    "def mssq_label(v: float) -> str:\n",
    "    if v <= 11.3:  return \"Low\"\n",
    "    if v <= 17.9:  return \"Medium\"\n",
    "    if v <= 25.9:  return \"High\"\n",
    "    return \"Very High\"\n",
    "\n",
    "label_order = [\"Low\", \"Medium\", \"High\", \"Very High\"]\n",
    "\n",
    "# seaborn Set2 から近い色（手動指定）\n",
    "SET2 = {\n",
    "    \"Low\":       \"#66c2a5\",  # greenish\n",
    "    \"Medium\":    \"#fc8d62\",  # orange\n",
    "    \"High\":      \"#8da0cb\",  # blue\n",
    "    \"Very High\": \"#e78ac3\",  # pink\n",
    "}\n",
    "\n",
    "VIM_COL = {\"Low\": \"#66c2a5\", \"High\": \"#e78ac3\"}  # 7点閾値の2色\n",
    "\n",
    "# 入力→表示の列名（軸ラベルに使う）\n",
    "DISPLAY = {\n",
    "    \"MSSQ\": \"MSSQ\",\n",
    "    \"VIMSSQ\": \"VIMSSQ\",\n",
    "    \"SSQ_TOTAL\": \"SSQ_Total\",\n",
    "    \"SSQ_NAUSEA\": \"SSQ_Nausea\",\n",
    "    \"FMS_MAX\": \"MAX_FMS\",\n",
    "}\n",
    "\n",
    "# ---------- prepare categorical columns ----------\n",
    "df_plot = df_in.copy()\n",
    "if \"MSSQ\" in df_plot.columns:\n",
    "    df_plot[\"MSSQ_label\"] = df_plot[\"MSSQ\"].astype(float).apply(mssq_label)\n",
    "\n",
    "if \"VIMSSQ\" in df_plot.columns:\n",
    "    df_plot[\"VIMSSQ_label\"] = np.where(pd.to_numeric(df_plot[\"VIMSSQ\"], errors=\"coerce\") < 7, \"Low\", \"High\")\n",
    "\n",
    "# ID列（subject_id優先、なければID）\n",
    "ID_COL = \"subject_id\" if \"subject_id\" in df_plot.columns else (\"ID\" if \"ID\" in df_plot.columns else None)\n",
    "\n",
    "# ---------- math: regression & 95% CI for the mean prediction ----------\n",
    "def regression_ci(x: np.ndarray, y: np.ndarray, x_grid: np.ndarray, alpha: float=0.05\n",
    "                 ) -> Tuple[float, float, float, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"OLS (with intercept) and 95% CI for mean prediction (yhat).\n",
    "    returns: slope, intercept, r, yhat_grid, lo_grid, hi_grid\n",
    "    \"\"\"\n",
    "    x = x.astype(float); y = y.astype(float)\n",
    "    n = x.size\n",
    "    xbar = x.mean(); ybar = y.mean()\n",
    "    Sxx = np.sum((x - xbar) ** 2)\n",
    "    if n < 3 or Sxx <= 0:\n",
    "        return (np.nan, np.nan, np.nan, np.full_like(x_grid, np.nan),)*2 + (np.full_like(x_grid, np.nan),)\n",
    "\n",
    "    slope = np.sum((x - xbar)*(y - ybar)) / Sxx\n",
    "    intercept = ybar - slope * xbar\n",
    "    yhat = slope * x + intercept\n",
    "    resid = y - yhat\n",
    "    s = np.sqrt(np.sum(resid**2) / (n - 2))  # residual std\n",
    "    r, _p = stats.pearsonr(x, y)\n",
    "\n",
    "    tcrit = stats.t.ppf(1 - alpha/2, df=n-2)\n",
    "    se_mean = lambda x0: s * np.sqrt(1/n + ( (x0 - xbar)**2 / Sxx ))\n",
    "\n",
    "    y_grid = slope * x_grid + intercept\n",
    "    se_grid = se_mean(x_grid)\n",
    "    lo_grid = y_grid - tcrit * se_grid\n",
    "    hi_grid = y_grid + tcrit * se_grid\n",
    "    return slope, intercept, r, y_grid, lo_grid, hi_grid\n",
    "\n",
    "# ---------- plotter ----------\n",
    "def plot_with_ci(df: pd.DataFrame, x_col: str, y_col: str, out_path: str) -> bool:\n",
    "    # data\n",
    "    x = pd.to_numeric(df[x_col], errors=\"coerce\").to_numpy()\n",
    "    y = pd.to_numeric(df[y_col], errors=\"coerce\").to_numpy()\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size < N_MIN or np.std(x) == 0 or np.std(y) == 0:\n",
    "        print(f\"[SKIP] {x_col} vs {y_col}: insufficient or constant data\")\n",
    "        return False\n",
    "\n",
    "    # regression & CI\n",
    "    x_grid = np.linspace(x.min(), x.max(), 300)\n",
    "    slope, intercept, r, y_grid, lo_grid, hi_grid = regression_ci(x, y, x_grid, alpha=0.05)\n",
    "    r_val, p_val = stats.pearsonr(x, y)\n",
    "\n",
    "    # figure\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # CI band\n",
    "    if np.all(np.isfinite(lo_grid)):\n",
    "        ax.fill_between(x_grid, lo_grid, hi_grid, color=\"gray\", alpha=0.30, label=\"95% CI\")\n",
    "\n",
    "    # scatter by groups\n",
    "    if x_col == \"MSSQ\" and \"MSSQ_label\" in df.columns:\n",
    "        for lab in label_order:\n",
    "            sub = df[df[\"MSSQ_label\"] == lab]\n",
    "            xs = pd.to_numeric(sub[x_col], errors=\"coerce\").to_numpy()\n",
    "            ys = pd.to_numeric(sub[y_col], errors=\"coerce\").to_numpy()\n",
    "            mm = np.isfinite(xs) & np.isfinite(ys)\n",
    "            ax.scatter(xs[mm], ys[mm], s=90, alpha=0.9, label=lab, color=SET2[lab])\n",
    "        for xv, lab in zip([11.3, 17.9, 25.9], [\"Medium\", \"High\", \"Very High\"]):\n",
    "            ax.axvline(xv, linestyle=\"dotted\", linewidth=LINEWIDTH, color=SET2[lab])\n",
    "    elif x_col == \"VIMSSQ\" and \"VIMSSQ_label\" in df.columns:\n",
    "        for lab in [\"Low\", \"High\"]:\n",
    "            sub = df[df[\"VIMSSQ_label\"] == lab]\n",
    "            xs = pd.to_numeric(sub[x_col], errors=\"coerce\").to_numpy()\n",
    "            ys = pd.to_numeric(sub[y_col], errors=\"coerce\").to_numpy()\n",
    "            mm = np.isfinite(xs) & np.isfinite(ys)\n",
    "            ax.scatter(xs[mm], ys[mm], s=90, alpha=0.9, label=lab, color=VIM_COL[lab])\n",
    "        ax.axvline(7.0, linestyle=\"dotted\", linewidth=LINEWIDTH, color=\"gray\")\n",
    "    else:\n",
    "        ax.scatter(x, y, s=90, alpha=0.9)\n",
    "\n",
    "    # regression line\n",
    "    if np.all(np.isfinite(y_grid)):\n",
    "        ax.plot(x_grid, y_grid, linestyle=\"--\", linewidth=LINEWIDTH, color=\"black\", label=\"Regression line\")\n",
    "\n",
    "    # ID labels (smaller)\n",
    "    if ID_COL is not None and ID_COL in df.columns:\n",
    "        dx = 0.01 * (x.max() - x.min() if x.max() > x.min() else 1.0)\n",
    "        dy = 0.01 * (y.max() - y.min() if y.max() > y.min() else 1.0)\n",
    "        for _, row in df[m].iterrows():\n",
    "            try:\n",
    "                xv = float(row[x_col]); yv = float(row[y_col])\n",
    "                ax.text(xv + dx, yv + dy, str(row[ID_COL]), fontsize=10, color=\"black\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # SSQ_Total threshold\n",
    "    if y_col == \"SSQ_TOTAL\":\n",
    "        ax.axhline(40, color=\"black\", linestyle=\"dotted\", linewidth=LINEWIDTH)\n",
    "        xmin = np.nanmin(x)\n",
    "        ax.text(xmin, 40 + 1.5, \"High Motion-Sickness\", fontsize=12, color=\"black\")\n",
    "\n",
    "    # stats box\n",
    "    ax.text(0.05, 0.95, f\"r = {r_val:.3f}\\np = {p_val:.4f}\",\n",
    "            transform=ax.transAxes, ha=\"left\", va=\"top\",\n",
    "            fontsize=16, bbox=dict(facecolor=\"white\", edgecolor=\"gray\", alpha=0.7))\n",
    "\n",
    "    # axes / legend (smaller)\n",
    "    ax.set_xlabel(DISPLAY.get(x_col, x_col), fontsize=LABEL_FSIZE)\n",
    "    ax.set_ylabel(DISPLAY.get(y_col, y_col), fontsize=LABEL_FSIZE)\n",
    "    ax.set_title(f\"{DISPLAY.get(x_col, x_col)} vs {DISPLAY.get(y_col, y_col)}\", fontsize=TITLE_FSIZE)\n",
    "    ax.tick_params(axis=\"both\", labelsize=TICK_FSIZE)\n",
    "    ax.grid(True)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if len(labels) > 0:\n",
    "        ax.legend(\n",
    "            loc=\"lower right\",\n",
    "            fontsize=12,           # ← 小さく\n",
    "            title=\"label\" if x_col in (\"MSSQ\", \"VIMSSQ\") else None,\n",
    "            title_fontsize=12,     # ← 小さく\n",
    "            handlelength=1.6, handletextpad=0.5,\n",
    "            borderpad=0.3, labelspacing=0.4\n",
    "        )\n",
    "\n",
    "    ensure_dirs(os.path.dirname(out_path))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"[OK]  {x_col} vs {y_col} -> {out_path}\")\n",
    "    return True\n",
    "\n",
    "# ---------- run & also record tables ----------\n",
    "init_tables(CORR_TABLE_PATH, REG_TABLE_PATH, overwrite=OVERWRITE_TABLES)\n",
    "\n",
    "pairs = [\n",
    "    (\"MSSQ\",   \"SSQ_TOTAL\"),\n",
    "    (\"MSSQ\",   \"SSQ_NAUSEA\"),\n",
    "    (\"MSSQ\",   \"FMS_MAX\"),\n",
    "    (\"VIMSSQ\", \"SSQ_TOTAL\"),\n",
    "    (\"VIMSSQ\", \"SSQ_NAUSEA\"),\n",
    "    (\"VIMSSQ\", \"FMS_MAX\"),\n",
    "    (\"MSSQ\",   \"VIMSSQ\"),  # 追加ペア\n",
    "]\n",
    "\n",
    "for x_col, y_col in pairs:\n",
    "    if (x_col not in df_plot.columns) or (y_col not in df_plot.columns):\n",
    "        print(f\"[SKIP] {x_col} vs {y_col}: missing column(s)\")\n",
    "        continue\n",
    "\n",
    "    # stats rows\n",
    "    x = pd.to_numeric(df_plot[x_col], errors=\"coerce\").to_numpy()\n",
    "    y = pd.to_numeric(df_plot[y_col], errors=\"coerce\").to_numpy()\n",
    "    n, r, p, r_lo, r_hi = compute_correlation(x, y)\n",
    "    if n < N_MIN or not np.isfinite(r):\n",
    "        print(f\"[SKIP] {x_col} vs {y_col}: insufficient data (N={n})\")\n",
    "        continue\n",
    "\n",
    "    append_corr_row(CORR_TABLE_PATH, {\n",
    "        \"x_var\": x_col, \"y_var\": y_col, \"method\": \"pearson\", \"N\": n,\n",
    "        \"r\": r, \"p_value\": p, \"r_ci_low\": r_lo, \"r_ci_high\": r_hi, \"note\": \"\"\n",
    "    })\n",
    "\n",
    "    n2, slope, intercept, r_val, r2, p_lin = compute_regression(x, y)\n",
    "    append_reg_row(REG_TABLE_PATH, {\n",
    "        \"x_var\": x_col, \"y_var\": y_col, \"slope\": slope, \"intercept\": intercept,\n",
    "        \"r_value\": r_val, \"r_squared\": r2, \"p_value\": p_lin, \"N\": n2\n",
    "    })\n",
    "\n",
    "    # figure\n",
    "    out_png = os.path.join(OUT_PLOTS_CORR, f\"{DISPLAY.get(x_col, x_col)}_vs_{DISPLAY.get(y_col, y_col)}.png\")\n",
    "    plot_with_ci(df_plot, x_col, y_col, out_png)\n",
    "\n",
    "print(f\"[OK]  Table(corr) -> {CORR_TABLE_PATH}\")\n",
    "print(f\"[OK]  Table(reg)  -> {REG_TABLE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08d03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【各被験者の MaxFMS・SSQ_Total・SSQ_Nausea】\n",
      "------------------------------------------------------------\n",
      "0521 因幡先生  : MaxFMS=2.0, SSQ_Total=11.2, SSQ_Nausea=9.5 -> Sick\n",
      "06021 今村さん  : MaxFMS=2.0, SSQ_Total=26.2, SSQ_Nausea=28.6 -> Sick\n",
      "06022 梅野さん  : MaxFMS=2.0, SSQ_Total=11.2, SSQ_Nausea=19.1 -> Sick\n",
      "06271       : MaxFMS=2.0, SSQ_Total=52.4, SSQ_Nausea=38.2 -> Sick\n",
      "06272       : MaxFMS=3.0, SSQ_Total=33.7, SSQ_Nausea=28.6 -> Sick\n",
      "06273       : MaxFMS=3.0, SSQ_Total=29.9, SSQ_Nausea=47.7 -> Sick\n",
      "06274       : MaxFMS=1.0, SSQ_Total=18.7, SSQ_Nausea=9.5 -> Non-Sick\n",
      "06275       : MaxFMS=0.0, SSQ_Total=0.0, SSQ_Nausea=0.0 -> Non-Sick\n",
      "------------------------------------------------------------\n",
      "[OK]  Plot -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\MaxFMS_vs_SSQ_Total_thresh19.png\n",
      "[OK]  Plot -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\correlation\\MaxFMS_vs_SSQ_Nausea_thresh19.png\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: MaxFMS vs SSQ plots (red OR-region, no CI) ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import pearsonr, linregress\n",
    "\n",
    "# しきい値\n",
    "X_THRESH = 1.9   # MaxFMS\n",
    "Y_THRESH = 19.0  # SSQ (Total/Nauseaともにここでは19を採用)\n",
    "\n",
    "# データ収集\n",
    "fms_peaks, ssq_totals, ssq_nauseas, labels, groups = [], [], [], [], []\n",
    "\n",
    "def classify(max_fms: float, ssq_value: float) -> str:\n",
    "    if not np.isfinite(max_fms) or not np.isfinite(ssq_value):\n",
    "        return \"Unclassified\"\n",
    "    return \"Sick\" if (max_fms >= X_THRESH or ssq_value >= Y_THRESH) else \"Non-Sick\"\n",
    "\n",
    "print(\"【各被験者の MaxFMS・SSQ_Total・SSQ_Nausea】\")\n",
    "print(\"-\" * 60)\n",
    "for subject_id, person_name in subjects:\n",
    "    folder = os.path.join(BASE_DIR, f\"{subject_id}{person_name}\", \"epoch_summary\")\n",
    "    scores_csv = os.path.join(folder, f\"{subject_id}_scores.csv\")\n",
    "    epoch_csv  = os.path.join(folder, f\"{subject_id}_all_epoch_summary.csv\")\n",
    "    try:\n",
    "        score_df = pd.read_csv(scores_csv)\n",
    "        epoch_df = pd.read_csv(epoch_csv)\n",
    "\n",
    "        # Max FMS（epoch summaryのFMS列を想定：3列目）\n",
    "        fms_series = pd.to_numeric(epoch_df.iloc[:, 2], errors=\"coerce\").dropna()\n",
    "        max_fms = float(fms_series.max()) if not fms_series.empty else np.nan\n",
    "\n",
    "        ssq_total  = float(pd.to_numeric(score_df.loc[0, \"SSQ_Total\"],  errors=\"coerce\"))\n",
    "        ssq_nausea = float(pd.to_numeric(score_df.loc[0, \"SSQ_Nausea\"], errors=\"coerce\"))\n",
    "\n",
    "        grp = classify(max_fms, ssq_total)\n",
    "\n",
    "        fms_peaks.append(max_fms)\n",
    "        ssq_totals.append(ssq_total)\n",
    "        ssq_nauseas.append(ssq_nausea)\n",
    "        labels.append(subject_id)\n",
    "        groups.append(grp)\n",
    "\n",
    "        print(f\"{subject_id} {person_name:<6}: MaxFMS={max_fms:.1f}, SSQ_Total={ssq_total:.1f}, SSQ_Nausea={ssq_nausea:.1f} -> {grp}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{subject_id} {person_name:<6}: 読み込みエラー: {e}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# カラー\n",
    "COLORS = {\"Sick\": \"red\", \"Non-Sick\": \"blue\", \"Unclassified\": \"gray\"}\n",
    "\n",
    "def plot_corr(x, y, x_label, y_label, title, out_png):\n",
    "    # ---- 有効データ抽出（配列化 & 同一マスク）----\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[m], y[m]\n",
    "    if x.size < 2:\n",
    "        print(f\"[SKIP] {title}: data < 2\")\n",
    "        return\n",
    "\n",
    "    # ラベル・グループも同じマスクでフィルタ\n",
    "    groups_f = np.asarray(groups, dtype=object)[m]\n",
    "    labels_f = np.asarray(labels, dtype=object)[m]\n",
    "\n",
    "    # ---- 相関・回帰 ----\n",
    "    r, p = pearsonr(x, y)\n",
    "    slope, intercept, *_ = linregress(x, y)\n",
    "\n",
    "    # ---- 軸範囲 ----\n",
    "    x_min, x_max = -0.5, 4.5\n",
    "    y_pad = max(5.0, 0.1 * (y.max() - y.min() + 1e-9))\n",
    "    y_min = np.floor(min(0.0, y.min() - y_pad))\n",
    "    y_max = np.ceil(y.max() + y_pad)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    # 背景：全体赤（OR領域）+ 左下のみ青（ANDで非該当領域）\n",
    "    ax.set_facecolor(\"mistyrose\")\n",
    "    rect = Rectangle((x_min, y_min), X_THRESH - x_min, Y_THRESH - y_min,\n",
    "                     facecolor=\"lightblue\", alpha=0.35, zorder=0)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # ---- 散布（グループ別）----\n",
    "    for grp in [\"Sick\", \"Non-Sick\", \"Unclassified\"]:\n",
    "        idx = np.where(groups_f == grp)[0]\n",
    "        if idx.size == 0:\n",
    "            continue\n",
    "        ax.scatter(x[idx], y[idx], s=90, color=COLORS[grp], label=grp)\n",
    "\n",
    "        # IDラベル（小さめ）\n",
    "        dx = 0.03 * (x_max - x_min)\n",
    "        dy = 0.02 * (y_max - y_min)\n",
    "        for j in idx:\n",
    "            ax.text(x[j] + dx, y[j] + dy, str(labels_f[j]), fontsize=10, color=\"black\")\n",
    "\n",
    "    # ---- 回帰線 ----\n",
    "    x_line = np.linspace(x_min, x_max, 100)\n",
    "    y_line = slope * x_line + intercept\n",
    "    ax.plot(x_line, y_line, linestyle=\"--\", color=\"gray\",\n",
    "            label=\"Regression Line\", linewidth=LINEWIDTH)\n",
    "\n",
    "    # r, p を右下に表示\n",
    "    ax.text(0.70, 0.15, f\"r = {r:.2f}\\np = {p:.3f}\",\n",
    "            transform=ax.transAxes, fontsize=16,\n",
    "            bbox=dict(facecolor=\"white\", edgecolor=\"gray\", alpha=0.7))\n",
    "\n",
    "    # ---- 体裁 ----\n",
    "    ax.set_xlabel(x_label, fontsize=LABEL_FSIZE)\n",
    "    ax.set_ylabel(y_label, fontsize=LABEL_FSIZE)\n",
    "    ax.set_title(title, fontsize=TITLE_FSIZE)\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks([0, 1, 2, 3, 4])\n",
    "    ax.tick_params(axis=\"both\", labelsize=TICK_FSIZE)\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc=\"upper left\", fontsize=12)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    ensure_dirs(OUT_PLOTS_CORR)\n",
    "    fig.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"[OK]  Plot -> {out_png}\")\n",
    "\n",
    "    # ---- 表に追記（任意）----\n",
    "    try:\n",
    "        n = x.size\n",
    "        append_corr_row(CORR_TABLE_PATH, {\n",
    "            \"x_var\": x_label.replace(\" \", \"_\"),\n",
    "            \"y_var\": y_label.replace(\" \", \"_\"),\n",
    "            \"method\": \"pearson\", \"N\": n,\n",
    "            \"r\": r, \"p_value\": p, \"r_ci_low\": np.nan, \"r_ci_high\": np.nan, \"note\": \"bg OR region; no CI\"\n",
    "        })\n",
    "        append_reg_row(REG_TABLE_PATH, {\n",
    "            \"x_var\": x_label.replace(\" \", \"_\"),\n",
    "            \"y_var\": y_label.replace(\" \", \"_\"),\n",
    "            \"slope\": slope, \"intercept\": intercept,\n",
    "            \"r_value\": r, \"r_squared\": r**2, \"p_value\": p, \"N\": n\n",
    "        })\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "# 実行（2図）\n",
    "plot_corr(fms_peaks, ssq_totals,\n",
    "          x_label=\"Max FMS\", y_label=\"SSQ Total\",\n",
    "          title=\"Max FMS vs SSQ Total\",\n",
    "          out_png=os.path.join(OUT_PLOTS_CORR, \"MaxFMS_vs_SSQ_Total_thresh19.png\"))\n",
    "\n",
    "plot_corr(fms_peaks, ssq_nauseas,\n",
    "          x_label=\"Max FMS\", y_label=\"SSQ Nausea\",\n",
    "          title=\"Max FMS vs SSQ Nausea\",\n",
    "          out_png=os.path.join(OUT_PLOTS_CORR, \"MaxFMS_vs_SSQ_Nausea_thresh19.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e64df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]  FMS histogram (80th) -> C:\\Users\\taiki\\OneDrive - Science Tokyo\\デスクトップ\\研究\\実験結果\\ANALYSIS\\plots\\distribution\\FMS_histogram_80th_percentile_position.png\n",
      "\n",
      "[FMS score stats]\n",
      "Total samples: 160\n",
      "80th percentile (value): 1.00\n",
      "80th percentile (score): 1\n",
      "Count FMS >= 2: 30 (18.8%)\n",
      "\n",
      "[Frequency by score]\n",
      "FMS = 0 : 81 (50.6%)\n",
      "FMS = 1 : 49 (30.6%)\n",
      "FMS = 2 : 25 (15.6%)\n",
      "FMS = 3 : 5 (3.1%)\n",
      "FMS = 4 : 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: FMS score distribution with 80th percentile position ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subfolder = \"epoch_summary\"\n",
    "\n",
    "# ---- すべての被験者の全エポックを結合 ----\n",
    "df_list = []\n",
    "for subject_id, name in subjects:\n",
    "    file_path = os.path.join(BASE_DIR, f\"{subject_id}{name}\", subfolder, f\"{subject_id}_all_epoch_summary.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"subject_id\"] = subject_id\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[SKIP] read: {file_path} ({e})\")\n",
    "    else:\n",
    "        print(f\"[SKIP] not found: {file_path}\")\n",
    "\n",
    "if len(df_list) == 0:\n",
    "    raise SystemExit(\"[SKIP] no epoch_summary CSVs\")\n",
    "\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# ---- FMS列を取得（列名ゆらぎに対応：'FMS'が無ければ3列目を試す）----\n",
    "if \"FMS\" in combined_df.columns:\n",
    "    fms_series = pd.to_numeric(combined_df[\"FMS\"], errors=\"coerce\").dropna()\n",
    "else:\n",
    "    fms_series = pd.to_numeric(combined_df.iloc[:, 2], errors=\"coerce\").dropna()\n",
    "\n",
    "# 整数化（FMSは0,1,2,3,4想定）\n",
    "fms_values = fms_series.astype(int).values\n",
    "if fms_values.size == 0:\n",
    "    raise SystemExit(\"[SKIP] no valid FMS values\")\n",
    "\n",
    "# ---- 80パーセンタイル計算（連続値と整数スコアの両方を報告）----\n",
    "percentile_80_value = float(np.percentile(fms_values, 80))\n",
    "sorted_fms = np.sort(fms_values)\n",
    "percentile_index = int(0.8 * len(sorted_fms))  # 参考コードに合わせてfloor\n",
    "percentile_index = min(max(percentile_index, 0), len(sorted_fms)-1)\n",
    "score_at_percentile = int(sorted_fms[percentile_index])\n",
    "\n",
    "# ---- スコアごとの件数 ----\n",
    "fms_counts = pd.Series(fms_values).value_counts().sort_index()\n",
    "\n",
    "# ---- ヒストグラム（ビンは0～4の整数）----\n",
    "bin_edges = np.arange(-0.5, 4.5 + 1, 1)  # [-0.5, 0.5, ..., 4.5]\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "n, bins, patches = ax.hist(fms_values, bins=bin_edges, edgecolor=\"black\", rwidth=0.8)\n",
    "\n",
    "# ---- 80thが属する棒の中での位置（高さ）を算出して水平線を引く ----\n",
    "target_score = score_at_percentile\n",
    "count_in_bin = int(fms_counts.get(target_score, 0))\n",
    "# 棒の中の並びで何番目か（0始まり）\n",
    "position_in_bin = int(percentile_index - np.sum(sorted_fms < target_score))\n",
    "# 棒の総高さを件数n[target_score]に対応させ、棒内の等間隔位置に水平線\n",
    "if 0 <= target_score < len(n) and count_in_bin > 0:\n",
    "    step_height = n[target_score] / count_in_bin\n",
    "    y_line = step_height * position_in_bin\n",
    "    ax.hlines(y=y_line,\n",
    "              xmin=target_score - 0.4, xmax=target_score + 0.4,\n",
    "              color=\"red\", linestyle=\"-\", linewidth=1.5,\n",
    "              label=f\"80th percentile in FMS = {target_score}\")\n",
    "else:\n",
    "    y_line = None\n",
    "\n",
    "# ---- 体裁 ----\n",
    "ax.set_xticks(np.arange(0, 5, 1))\n",
    "ax.set_xlabel(\"FMS Score\", fontsize=24)\n",
    "ax.set_ylabel(\"Frequency\", fontsize=24)\n",
    "ax.set_title(\"FMS Score Distribution\", fontsize=30)\n",
    "ax.tick_params(axis=\"both\", labelsize=20)\n",
    "ax.grid(True)\n",
    "ax.legend(fontsize=12, loc=\"upper right\")\n",
    "\n",
    "ensure_dirs(OUT_PLOTS_DIST)\n",
    "out_png = os.path.join(OUT_PLOTS_DIST, \"FMS_histogram_80th_percentile_position.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(out_png, dpi=200, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(f\"[OK]  FMS histogram (80th) -> {out_png}\")\n",
    "\n",
    "# ---- 統計情報出力 ----\n",
    "total = len(fms_values)\n",
    "num_ge_threshold = int(np.sum(fms_values >= 2))\n",
    "print(\"\\n[FMS score stats]\")\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"80th percentile (value): {percentile_80_value:.2f}\")\n",
    "print(f\"80th percentile (score): {score_at_percentile}\")\n",
    "print(f\"Count FMS >= 2: {num_ge_threshold} ({num_ge_threshold / total * 100:.1f}%)\\n\")\n",
    "\n",
    "print(\"[Frequency by score]\")\n",
    "for score in range(0, 5):\n",
    "    cnt = int(fms_counts.get(score, 0))\n",
    "    pct = cnt / total * 100\n",
    "    print(f\"FMS = {score} : {cnt} ({pct:.1f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
